{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Microexpression-recognition-tesis-maestria-MicroExpSTCNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNJziXfQvHAT2TGM5Kq/HdR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/natzasu13/microexpresion-recognition/blob/negative-microexpresions/Microexpression_recognition_tesis_maestria_MicroExpSTCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwfN_fFdCe_C"
      },
      "source": [
        ""
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttedfsEvCkgz"
      },
      "source": [
        "#**Microexpresion recognition**\n",
        "**MicroExpSTCNN Model**\n",
        "\n",
        "Natalia Zartha\n",
        "Maestria en Ingenira de Sistemas y Computaci√≥n, 2021"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ltuuhwD-pft"
      },
      "source": [
        "![micro.JPG](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/4RD4RXhpZgAATU0AKgAAAAgABAE7AAIAAAAPAAAISodpAAQAAAABAAAIWpydAAEAAAAeAAAQ0uocAAcAAAgMAAAAPgAAAAAc6gAAAAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAE5BVEFMSUEtWkFSVEhBAAAABZADAAIAAAAUAAAQqJAEAAIAAAAUAAAQvJKRAAIAAAADMTYAAJKSAAIAAAADMTYAAOocAAcAAAgMAAAInAAAAAAc6gAAAAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADIwMjE6MDc6MTUgMjA6NDI6MzcAMjAyMTowNzoxNSAyMDo0MjozNwAAAE4AQQBUAEEATABJAEEALQBaAEEAUgBUAEgAQQAAAP/hCyFodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvADw/eHBhY2tldCBiZWdpbj0n77u/JyBpZD0nVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkJz8+DQo8eDp4bXBtZXRhIHhtbG5zOng9ImFkb2JlOm5zOm1ldGEvIj48cmRmOlJERiB4bWxuczpyZGY9Imh0dHA6Ly93d3cudzMub3JnLzE5OTkvMDIvMjItcmRmLXN5bnRheC1ucyMiPjxyZGY6RGVzY3JpcHRpb24gcmRmOmFib3V0PSJ1dWlkOmZhZjViZGQ1LWJhM2QtMTFkYS1hZDMxLWQzM2Q3NTE4MmYxYiIgeG1sbnM6ZGM9Imh0dHA6Ly9wdXJsLm9yZy9kYy9lbGVtZW50cy8xLjEvIi8+PHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9InV1aWQ6ZmFmNWJkZDUtYmEzZC0xMWRhLWFkMzEtZDMzZDc1MTgyZjFiIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iPjx4bXA6Q3JlYXRlRGF0ZT4yMDIxLTA3LTE1VDIwOjQyOjM3LjE2MjwveG1wOkNyZWF0ZURhdGU+PC9yZGY6RGVzY3JpcHRpb24+PHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9InV1aWQ6ZmFmNWJkZDUtYmEzZC0xMWRhLWFkMzEtZDMzZDc1MTgyZjFiIiB4bWxuczpkYz0iaHR0cDovL3B1cmwub3JnL2RjL2VsZW1lbnRzLzEuMS8iPjxkYzpjcmVhdG9yPjxyZGY6U2VxIHhtbG5zOnJkZj0iaHR0cDovL3d3dy53My5vcmcvMTk5OS8wMi8yMi1yZGYtc3ludGF4LW5zIyI+PHJkZjpsaT5OQVRBTElBLVpBUlRIQTwvcmRmOmxpPjwvcmRmOlNlcT4NCgkJCTwvZGM6Y3JlYXRvcj48L3JkZjpEZXNjcmlwdGlvbj48L3JkZjpSREY+PC94OnhtcG1ldGE+DQogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgIDw/eHBhY2tldCBlbmQ9J3cnPz7/2wBDAAcFBQYFBAcGBQYIBwcIChELCgkJChUPEAwRGBUaGRgVGBcbHichGx0lHRcYIi4iJSgpKywrGiAvMy8qMicqKyr/2wBDAQcICAoJChQLCxQqHBgcKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKir/wAARCAEkBD0DASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD6RooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigArlviBrGr6Z4ce38KG2PiC9DrYR3CswJRGkchQDkhVIGfl3sgPXB6muIgtr/AMUeOL/UY77VtGtdMhFhZFbMRGfftknkxPCQykrEoI7xP2OSAbng3xPa+MvB2m+ILDIivod5UgjY4JV0567XDDPQ4yOKbF400CbUoLGO+PmXErQQStBIsE0i53IkxXy3YYI2hiflb0OPOvCmh6xoepeOvAtsNTbT7+KW50jU7i0eOCOWWMiRDIqBVw5BG3jgkAE4PReBNSWfwp4c0PUPDWpw6ppVvFBKt9pzxxWzxJ5bSpMy+WwIzt2MWIYcAbiADopPG2gQ6tFp0t66SzXf2KKVraUQPcYP7oTbfLL5BXG7O4FfvDFPvfGGh6dqlpp97eNDNeXH2W3dreTyZJucRCXbs35UjbuzkYxXE/Dm5uNN8EaV4U1fwxqMmtaZK8eLqxdbXzEZnWcXJUx7ckYZSXz0U1leFdBs4vD48M+MND8RXeq2t68ZQPftp94fOLxzq4YwheVYlsEMG+XOBQB6DqHxD8M6ZfX9lc30z3WnbDeQ21lPO0AcMylhGjYGFJz0GVzjcMw3fxC0iHxJoekWq3N4dYjaeG5t7aSSExBQQwdQQ2Sy8jIAJLEcZ5jwrfw2Pxz+JzTpcMCNLP7i2kmPFq3ZFP5d+1YPh7QtQ8FXHgC5vND1Bba0tNUMttZQS3jWhnkEkULFVzkBtpZsDIPOOaAPWL/xVo+l6pBYX9y8E1xMtvG7W8nlGVhlYzLt2Bj2UsCcj1GW65rdnbM+l/bLu3vpoN6vZWjTvbqSVWRsRuiAkHBkGDtbrtOPNNC8OabLZ6p4W8b6B4iuJ21O4dVRr1rG9SSdpY3DRt5K9VJ3bSCORnNbuk3N74d+InixNb0vUzFrLQXVnd2lnLdQELAsbRl41JVgynhguRz3GQDa+FWrX2u/C7RNU1a4a5vbuFpZpmABZi7dhwB6AYAHA4q+1/b/APCwxZtrr+culvINGEQ27RIm64LYzn5lQDOPvYB5xj/B23ubL4S6HZX9pdWd1awmOaC6t3hdG3E9GAPQjkcVWkt7pf2il1A2V4bFfC7WpuhayGLzftKvs3gbc7ecZoA2LT4k+Er+O1ls9ZjngurhrWO4SKQwiVW27Gk27UJJG3cRuyCuciuorxnVI7vUPhVFa2uk6s1yPE73RhbS7hHETak8wfayA48tg3t354r2VGDorDOGGRkEH8j0oA888eSeL9D8L6r4psvEf2R9PLXKaUbSGa2kgTpG7FRJvYDLMrgDJAzjcblh4j1TxF8SL/RLWZtPsdG02CS+CRqZTdXHzooLgjasanoByeelZ3iPxxBL4g+w3nhHxde2Gm3CTJJZ6NO0dxOhyrZ43IrAEcEFlDDhQWn0K2vtH+Jeta9e6XdxWfibT7W4JVGma1mg3R+S6opwxjdWJ6BgygtjNAGn4P8AEl54o8P6tbRXUaato+pXGlT3MluCjvE+BL5asPvJtOMgBt2OAM8no3xL1iD9mf8A4TrVNt/qgjmJ4WJSxumiTgDGFBXjHO3k5Oa6L4c6ReaLp3iHVtXjnSTWtaudRjidHaaOBiFjR0wSGCr0GcDHpWV8H7BLH4C2ek+LbKWwjht7pdQg1KB4FWJ5pSd28AbdhyT2B5oA1Na8R3/hbUPCFxLqf9r6XrN4mmXDrHGC0syZhmj2gDbuQ5yx+VuATXcupaNlVihIwGXGR788V5bZ+BYdW8X+H0tbTUbbwx4RZpLb+0Zpt11c/wACoj4YRxYBDtweFUFcmvUncRxs7ZIUEnapJ/ADk0AeY+C/G8tnpPjLWPHHiGV7DRfEF1pkUk0EYWOKMoEJEUYJYlse/HFdjY+NdA1O8uLWwvXnngthd7EtpczQnpJF8v75egzHu5IHUivJre2vx8MPifZnRtYFzqmvXtzZQnSrgNcRSmMIyjZyDg/THOK7jE1x8eLLUo7K++w/8I7Lbm5eylSMSG4RwhYqADtBOD6UAa3hX4gaT4q8MHXIFuba085o1a4tpED/AL5ok2kjDlio+VSSCwB54qR/iJ4Wi07U7251T7NFpJUXy3NvLFJblhlN0bKHG7+Hj5u2a8m0zS9bsvg/4e0dtD1hr/w1rLXmqWcVvcRPLB9onBEEibRK+2USL5bkfJknoD0niW10hvBfiyfw/wCG/EN9dX+ktZtNd217LPNI25YkWO4BcqhJctwF+XGSeADr7r4neD7Ca4jv9YFoba5S1la5t5YlEj7tmGZQCpCMdwJXAJzjmr9l4z0C+g1OWPUBCukn/ThdxPbtbjGQzLIFO0gEhuhwcE4NYXjqUXWi+GpNOsL+SJdbspvLh06YtFEkgLFkCbkAA/iArmNXk1ew8QfE7UtO8LXGtG7stPWztLuxkMN5sV1kGCuJAobJQctjA60Aeh2vjTRL1Z/s89wZbe3W6a3eymSdoWJAkWJkDupIIyoIzXPnx1pfiP4bx+IP7TvvDtnLcxMt0bV/MCiddqgFSrbwApI3LlyOcVh6Mty3xej1Iwa5c2l54ZFgl5e6TLB/pAnZyjgRKsY2kYJAU9ASawhDqM/7NcHhtND1oapZfY0lgfTJ1JYXauwXK/NtVckjK8jmgD2LU/Emm6TdLa3Uk8ly0Zm8i1tZbmRUzjcViViq54BIAJBx0NVZvHPhiC30yeTXLLyNWdo7GVZQyTsoJYKw44wR9cL1IB5zRrTUdD+MHijVL20uZdK8QWlnNZ3MUTyeSYE2NE6BdyMTIWGRgjPfIGNoel3nhtdA+2WWoeTN4sv9QjhgspZvsltJBcxx7hGh8sFpUOG5G85xtYKAdynjvw22h6hq0mpi3tNMx9t+1QyQSW+QCoaJ1DgsCNo2/NkYzmprTXtP8SQalZ6RqFxbXloBHODbmG4ti67kby5k7jkEqVOD1wa8z1p9V0/X/iJeW3hi+1SG/vNMEW7TWmBRIkR5o42XEzRtghR3GegJrY8HmbT/AIm+LL27t9ZktdYs7CSzvLnTJlM/lRSLJvxGBGwP8DBScjAwRQBv/CfVr7XvhbouqavcvdXt3E8s0z4BZjI3YcAdgBgAcDiofizqmq6J4GfU9C1SfTrqG6t490UUTh1kmSMgiRG6BiRjHIHUcUnwctLrT/hHoVlqFpc2d1bwsksFzA0Tod7HlWAPQiqvxNNx4j0W78L6Zp2oPefarCRZzZyfZ2H2lGbEuNvyKuW9Ae/IAB12oa3ZaJ9mgv5riaecN5aQ2rzyyBcbm2RKTtGVBbAALKOpGcXW/Eej6h4fsL218Svp9rJqVugnt4yzyOJlBt2XGULNhWBGQM5GM1Se11HRvjLcaxPZT3OlatpcdqtxbI8ptpYWZtrooJCsHOGHGRg9a4m/8N6taeH9RkWw1GSPUfHEepW1olu0hit1mTdKVVNyBtrNhui7e+SQD1G/8b+HtN1S70y41DfqFnHHLNZ28Ek8wV87SI0Us3TJ2g7QQTgEE0dY+I+iaba6JcWxuNRh1u4SK0msraSaMg5JOVB5AVvlGWz2xkgtL5YvijrLvaagIpNIskSb+z5/KZo5Lp3UPs2khZo+M5ySOoIHm2habqenfC34aNeaPqiPo+s+ZfQLp8zzQJif5jEqlyPmXkA9aAPdVO5QRnBGeRiuB8FeJrz4jXWo65pmqzWWg2l29laW8EMZa62AEzO0iFgDuGEAUjbyTkiu5tLj7XZQXIilh86NZPKmTa6ZGdrDsR0I9a81+GelS/DRtV8JXun6m9m1/Ld6bqEdq08c0LKuFdowdki7SCGCg9R1oA63T11fRdZ1u41/WGutCjtori1uLpIYvs5BlMysUC5CgRncQBggckMTZsfFuj6heizinnhumhM6QXdnNbSSIOrIsqKWA4zjOMjPWub+IUOqeKvB91D4e0u5klsLq3vI1ulNuLwwy72iQMN2fkGCyhTuGCecM1q1ufEfxC8Fa1p9rqNpBpcd3cXkktu0TIjxKoiKuh3MzEDA5AVsc4IANfT/AImeENVay/s/WFnS+uDawTLBL5RmH/LMybdqueysQWyMZyM4k3imfxP4/wBf8L6VqeraQ2lQ2sSTQ6YXX7Q7O7OxZDhNqRhdxRWy/wB8YNcuLW/l+HHg22XSNW8+08WRXc8TabOrxQi8kcuylMgbWU5966TwvaXifGD4iTy2V7Bb6kmnpZ3MtpKkUpjt3V8OVxweOtAHYDxXow1uLSHu3S8mZ44fNt5EjmdPvqkhUI7DnKqSeG44OKknxA8Mx3aWx1Fmke/Gmjy7aV1W4Pl4RmCkLzNGMkgZbGcggcF4G0PT5PDui6V4i8Oa+PEGhyRmOC8e++xC4hOFnSTc0AXvkf7WFxwdaG0l1uw+JthpumXlle6q8q2kl1YyW6zg2MUKsJGUKR5iyHrkZyQM0AdjYeL9D1LVI9PtLxjczRGaBZbeSNbiMdXiZlCyL0OUJGCD3FZv/C0PB2Cw1pDGlwbaWYQSmO3kD7MSvt2xAtwGcgN1BIrn/B9tpmoHQr+Tw7rsHiCwXa0eqm/WGxLIUmMbTF4yCoIUKWJygJXkrzHiuy1HU/gN4z02x0fVpb6516eWC2/s2dZJUe/EqsqlASNnORwOh54oA9Z1zxdo3hwyDVbiZDDAbmbyLSafyYhn55PLVti8NgtjO1sfdOJL/wAT6Tp1jBeTXDzwXERnhazt5LkvEACZAIlYlcMvzYx8w55FcTYXsvhzx14vGsaFq95Z620N3ZS2umyXMc6eQsZhbaD5bZUjEm0Y5JAqLWrR9P8AiTb3uraLrEejXWjx2kUmhNdMbSSKWVgjrakEKUkX+FgGGAcAkgHpNhf2mqafDfadcR3VrOoeKaJtyuvqDVbVNdsNHlgivHmaa43GKG2tpLiRguNzbI1ZtoyoLYwCyjOSM1vCemWOjeHotP0bTjpumwu/2WB2cvsZixZg/wAykszHBJOMdCdo582uo6L8ZLrVriymudJ1fTI7dLi2R5TbSwszbXRVJCsHbDDjIx3oA17v4geFrDRrXVr3WreCwurj7NHO+4AS85RuMoRg5DYxg5xir2i+JtJ8QTXsGl3DvPYyCO5hmgkhkiJGVJSRVO0jo2MHBwTg15ZHoWpaVZzXEljqTQ6h48XUre2jtXmMNuJRulZUj3IG2lsN0G3vknq/CkNynxh8cXktleRWt5Fpwtp5bWRI5THHIH2sygHBI/OgDc8cLrJ8K3B8M6kdP1RmjitpCiMnmPIijfuRvl55wM4J74rB8O+NLvxZ4I1q3eU6N4q0eJ7fUYkjVvstwFbDqrblZGKkjqCAee9dH4svRZaRE5try5xeWzlLO0knYKtxGWbaik4AyfXAOM1yXxJ8J6hNt8a+Co5P7etLZop7NUKjVLZhgxSLkHcoJZc5OQBgnGADsvt6+H9HtYtav7jULtYf3k0Vmzy3BXAZxFCpIGSOgwMiqlj4+8NaldaPBYal9obXI5JNPdIJDHOEDFwH27QyhGypIIxyORXMeL7Ca0+KlhrOpWmsXOh3OlNYmTRmuzLaTrIZAzrbkN5bqcZAb5lXOOpzb/SINF1vwZ4h0PQNUj0ax1O+a5iS3uLi7P2iFk+0PEwMgBcEnOWwVOMnAAO7Pjrw8kWsyS30kS6Hj+0RLayoYMqXBwygsCoyCucjHqKhj+InheYXJj1PP2Z4Y2H2eUGR5WZI1jG396xaN1wm4gqwOCDXBXP2y4m+LMx0PWAusWUQ09G06Um5xZ+WNuFPO4j5Thh0IBBA39evbmz8A+FfsWh3dwn2m0jmdNLaafTECczpA0ZYOuMA7TjdnB6EAf8AELxgT8Ktf1jwlq81pfaWMORAFlicEApJHKmVyGzyAcYIOK76Ek28ZJySoyfwrwnWrPUJfCfxO06DStbuLnVbiO4sd2l3GblPLiGQ3lhc5B+XgjB44r3O0cSWcLAMoKDh0KkcdweRQB5l4v8AG+ueCPiQ91eTvd+Dbeytn1NPJjMtm9xLOkcqbQrMoaJQQSxw3AJ6dbPd3l3450QadrLjSbrTrm7eCOONkn2NAEIcqWAImJ4PNQWvl3vxI1+K60+6azuNKs7XfcWT+ROUkujIu5l2sMSrkZ5z3rnPBnhLWvB3xMGkjzbrwtDp13Lpdy+WNqZZrfdals9F8vcvTIZuuDgA7VvGOhJqsOnyXrJNPO1tC7QSCGSZSQ0SyldhcEMNobOVbjg1haX8VtCvrHxHqF2t5ZafoV69tLPLYz8hBGGYgIcEO5Gz7wA3EAZxyXgrR4IvDenaR4k8Pa5L4j0a5Aiile/+wSzRP+6uFky0IU5DE+u/CdFOx8OtNktbzx1oGv6VdoNT8QX94vn2bm3ntZQgB8wr5bbgSNuSeDkcGgDrj420Jdb0rSJJ7mK+1eNpbKKWxnTzlUEtyUAUgDJBIIBB7jMy+LdFayv7sXjCHT7s2NwWgkB88EDy1UrmQksoGwHcSAM15Q3hnxRpnhzS9YS1u77VfAdw1jpdl5Hl/wBo2/mGJ3G0k4e3MOD/AAtG2QQTXVeJPD+s6SPB2p2cbaydEv3n1NYE8uS4M6sks6RKCCQ0rvsHOOM96AOpHjTQfsmoXEl60C6bF515HcW8kUsEeCQ7RsofaQDg4wcGuY8R+NLDXdGY+FNfule3u7CO5W3hMayw3N0kB/eOmc481cxsGV1IJBXAzfFekXl7428QeILKy1BrH/hEZdPaNLZy15cO8hRFiKbmKjqw/vKP72b+seZ/wprRLaOw1LzojpReCHT5mmjENxbtJ+7CFgVVWOMdjjNAHXv4p0mPVLuwkmnjkshuuZXtJlghGzzDunK+Wvy88t3HqKl0rxDp+s3E8FibnzIESR1ns5YPlcsFZfMVdwOxuRnp9K4LTL3VNN8KeJPC3iXQ7/WktLKZrKdLaf8A4nNu6MQkkix/LOeFfPzFmyAeSb3gLTNX8P8AiK40h7i71XQUsg+n32oWjRXFr8+PsrOwBkULhgcAjkY4FAHVeLPEMXhXwveavNH5pgULFEW2+ZIzBETPYFmUZwcZzXL/ABEvfEPh7wLaXVp4glh1H+0LaGae3tYQjrLKqMoSRX2qAx28k8DJbnN74rRzH4eXVxBBFcfYrm1vZI5l3IY4biOR9w7qFViR6A1T+MSzz+DLaCzsr29mbU7SXy7OzluCESZXZiI1OAFBPPXoOaAJvidqOr6L4d0uXRtYuLGeXVbW0lljihcuksgRsh42AODkYA59uKRfEGqeIPiRe+F9GvHsbHw/DDJql75aNPcSyjdHEgZSqoVBLNtz2G3rVP4gTXHiVbLRdM0rUzNa6xp1y08llIsDR7w7MJCMfKB8wOCDxSxWF/4P+MOs6y1hdXui+KIbZZLm1haZ7O5hVkVWjTLeWy878YBIBwOaAOoGl61Fr6zLr9zNpssLK9tJBBmKT5dro4QHHDZBDcnqAMVxvhHxvq+neNrnwr45uDOb+6uDoGoeUo+0xxSujRSFFVRIoQH7oBz15XPejWUe68qKyvnjVC8sxtXRY/QYYBnJweEDYxzjIzyj+HLL4h/Duex1C3vdNllvLi5tpbi0aG5spTcO8cihwCCARyDyCRnmgCyr61Hp/jDzfEF08lhcSCzkW3gUwp9ljlC/6shsNIeSOcCqnw/8XapqM994Q8ZvHB4t0qPdO9uoCXUJxsuI+MH7y5GBgn7o6Cl4ebxHZfDzxSfF9lcTawZpoT9jtnkN6UtY41ljVRyJPLz0AyccdK0vG/hZ/F2l2HiDwzLNYeItLP2rTZ5IXheXAObeVW2sI36EHGM+mQQB7X2s+GPANtrur63Jq5sUNzqLPaxR+dAeW2qgG1kXkf3tpBHzAr2cUsc8KTQuskcihkdTkMCMgiuC8UXFy37P122pWTQX11oiwtZMrFhcSxhFiAHJbewUDrnFdppFrJY6HY2k23zLe2jifacjKqAcflQBcooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigDnNH8Iro/jXX/EUd4ZJNdMH2iFosKghQomw544POc5PTFdHRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAAQGBBGQeCD3qtYWEOm2otrTKWyYEMAACQIAAEQAcKMcDnGcDAAAs0UAFFFFABRRRQAUUUUAV5rKG5uoZ5wZDAd0St91GwRux64JGe3arFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAVleKby40/whq95Yy+Tc29lLJFJtDbGCEg4PBwfWtWsTxr/wAiHrv/AGD5/wD0WaBx3R5K/izxnDMYZ/E9yJF54tLbDD1H7qj/AIS7xh/0NFz/AOAlt/8AGqsXlol3Dtb5WXlHHVT/AJ7VytrdX11ZwzrBbgSxq4BmbjIz/dryJVaq1Uj9EpYHAv3ZUlc6L/hLvGH/AENFz/4CW3/xqr+geOfElt4ihGp6rJqlo0LtJBJBDGeCvKlEU5GT14P6jjH1GSNyjvYKynBBusEf+O0W+rNBfpc+bp7bY2Tb9r65KnP3f9miNarfVirZdgZQcYwVz6Ssr231CzjubOUSwyDKsP5H0PtU9eJeEPH0mn+ILW2kksVs72YRzAXmQpPRxkDB6Z9R+FevLr2kOwVNVsmZjgAXCEk/nXp05qcbnw2MwssLV9m/l6F+iiitDkCiiigAooooAKKKKACiio7kkWspHBCHB/CgCSivgZ/F3iNZWH9v6njJx/pkn+NJ/wAJd4j/AOg/qf8A4GSf417sclqyV+ZfiZe0R99UV8C/8Jd4j/6D+p/+Bkn+NWtK+IPirR9WttQtddvnlt5A4Sa4d0b2ZScEHpRLJayV+ZB7RH3hRXG/Db4j6Z8RPD4urUrBfwgLd2Zb5om9R6qex/DrXZV4s4SpycZKzRruFFFFQAUUUUAFFFFABRRRQAUUUUAFFY/inxNZeEdEbVNSjnkgV1QrbqGbJ9iQP1rjh8cvDZGRYasR/wBcY/8A45Wc6tODtOSRrCjUqK8It/I9Jorzb/hePhz/AKB+r/8AfmP/AOOUf8Lx8Of9A/V/+/Mf/wAcqPrND+dfei/qtf8Akf3M9JorkfCvxL0Lxbqcun2Iuba6jQSLHdoqGQc/dwxzjHIrrq1jKMleLuYyjKDtJWYUUUVRIUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAVj6prRtJVjtPLkcEiQMfu9Mf1rTupvs1pLNt3eWpbGetceZDd3kl0UwJDnb6UyWzXTXLpusUX4E099bljTc6xD61nxqOu2ue8aa+NB0Ka7KBuNoGeuaTdkJXZj+MPjXdaNfiz0SGxu5FJEhcMQD6cEVyU37RXiVVUpaaQpI5DQSnn0+/Xn0TveXklybd7hxJ5hTcQDn8KurPBJPibw4xU8ArcEc/wDfNYObudMYK2p3Fv8AtA+LJF/eWWjj6Qy//F1cg+O3iaZubXSFQfeYxS8f+PVyNoI8KieFZJGB7zH/AOJrUu7n7JapEfDcNssgwxMx+X6/LUSqs0VNG9J8dfEUW5jb6S68bQIpAW/N67Hwh498U61GZNX0e1t48/K8R4I/77NeBLHba9rsVm7tar0DAbgPbtXv/hbRxpGkxQidrkbR8zIF7fWtYNtanPUsnZHWHXrgLkxxj/P1rm/E3xJk0K0YKkH2plzEjozA898GrV1Mqqd0Zx7CvHPFOrvqeqMyW6xiImMfOTkA9eldNKHPI4q9Z043W511n8YvEt3MNtnp7RAgMVhkyP8Ax+tZfijrLSqqw2JyRn904/8AZq4HSrZ7a184FW80A46Yq5CS0yMeu4cA+9dbpw7HnqvV7n0TRRRXAe2FYnjX/kQ9d/7B8/8A6LNbdYnjX/kQ9d/7B8//AKLNJ7FR+JHmh6GuR0j/AJAlj/17x/8AoIrrj0NcjpH/ACBLH/r3j/8AQRXiz2P0/D/xPl/kXLfTs6eLm2TLmSTzIwPv/O3I9/501djqGUAg+1a2jf8AIMX/AK6Sf+jGrE1HT4Z9YuyxmTDLxHM6DlQTwpAokla4Uakk+Vak20eg/Ko540eNVZFZTIgII6jcKrf2Rbf89Lr/AMCpP/iqDo9ser3XXP8Ax9Sf/FVmrJ3OmaqSi42Wvn/wD2Pwn4pLNHpmqyZdjtt52/i4+4x9fQ9+B169nXzZJYr5bZubzp/z+S//ABVfQXh6R5vDOlyzOzyPZxMzMcliUGSTXrYer7RW7HwOcYD6pUUlopX09P8AhzRooorpPDCiiigAooooAKiuv+POb/rm38qlqK6/485v+ubfyoA/PSX/AFj/AFNRrkjqetSSf61/941GvT8TX6Glfl9P8jkEzyRluPajPu35UoGS3rn+lLuHfg1CTe7/AK+8ZveB/E934S8ZafqtneS2qxzItwyrkNCWG9SMcjGeP619U/8ADQfw5/6DM3/gFN/8TXxxuX1FIWG08jpXDisBRxD55S1RUZNH6GafqFpqunwX2nTx3FrcIJIpY2yrKe9WK+P/AIO/GCbwHqC6ZrErTaBcP86/ea1Y/wAaj09V/Hr1+urO8t9Qs4ruxnjuLeZA8csbbldT0INfMYrCyw0+V6rozaMromooorkKCiiigAooooAKKKKAOB+M3/JP2/6+4v5mvntiLYFicQ98n7n/ANb+VfQnxm/5J+3/AF9xfzNfPOo/8g24/wCuZr53M9cRFeS/Nn02VaYaT83+SH/bLb/n4i/77FH2y2/5+Iv++xUjHCEjsKo26XMiL5t7IrsobhEwfpxXlqMWr/1+R68pSTt/X5k9pqK2msG6trtYZI1jaOVJACrAscg+tfRPw4+I1p4wtfsV1NCurwJukRGGJlHG9R+IyO1fOv2af/n+l/74T/4mtHQtT1Tw5q66lpeoOlysbRAvFGw2tjPBX2Fd+ExSoT1fu9f6sedjMI8RDRe8tv6ufWlFfPNj8YPFdnqtpJf3cV7amXE0Bt0Teu09GUAg8V7voutWXiDSYdQ0yYSwSj8UPdSOxFe/RxNKv8DPnK+Fq0PjRfoooroOYKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooA8ystMOr6jrM95qerBk1S4iRYdTnjRUVsABVYACifTtIt9WttMn1zWEvbtHeGE6xc7nVfvH7/v8Az9DV3w9/rtc/7DF1/wCh1yOq6T4gvNW1PxHZ2MSz2t1GbQSs4meG3LZRF24/eb5h15Dj0FIvodb/AMIxb/8AQT1v/wAHFz/8XR/wjFv/ANBPW/8AwcXP/wAXXLzaReSfbdVhtr0X3/CQW727EuGW3LQh8L2TaXzxjrnpVG1Se11zSIL+1v11dtdma4uyW8qaEiZkAbOGGzZhR93ac4oGdt/wjFv/ANBPW/8AwcXP/wAXR/wjFv8A9BPW/wDwcXP/AMXXEaBYaskm2+a6j1SK3uFugunTr9oYqes5cxv82Cu0Z7DHIruvC+mR6X4dsolidJmgjacyMS7SbBksTzmgDX+H7yt4ZlSe4nuDDqF3Cj3ErSPsWd1UFmJJwABzXT1y/wAP/wDkX7v/ALCt9/6UyV1FMzCiiigAooooAKKKKACiiuPtdUv5lybp/wAhzQJuxPdandz3N1aGRTFuZCNvb61FDFtUKqgAU5It0jO2NzElj6msjxNq/wDY+kTzxybJVQlOM5Ipt2RO5oajeiwtJJC6qVBxnufSvn7WfEmueLb9raT95bySELGkYHC9Klg1vxh4lm8hr+4kikQuFOMDJwO1OsvA3jCCXzdOlmXYckqRznvXPOor2OmnTe5DZaT4yspH/s2P7x3N/oyNn8xXQWq+PfJQeXAFJ432cfB/75q3baH8QItuNWniLDuRkfpVjULLxdZ2m6XX7mSXOSRj8ulc7l6HSo+oyQeNrW1aa4vIElI4C20f/wATXGa/4s1lJlgvJUl3HDFoVXPqOBSX/jDX7bVYoZ7+Zot/KyEHcM8jpXrWl+GND17TYrjUtKt5ZGGSXU5/nVwptu7MalVLTUx/CHgzw7qdvDqpsGFzwwbz3A6emcV6CQbaEJCqhVHAJqtHYw6ZbiHT4o4Y0GFUdhXm/ivxDrMGu3EMOoSwou0BIzwOK7adNydkedVqqC5maHjLxLq9hqqwWdwII/LBI2K2Tk88iuU0y0Go+fLduzvuzkADJP0q7ah9XtfP1KR7mUHaHc84FWLK3S380RLgHFehCCgrdTyqlR1JX6CwqYozFuJRQAoI6VLbqBIjHkZ/rSxAFn3DtVW5v7exeIzyLGGcKu49TmmyEj6OooorzT6AKr6hYw6nptzYXYJguYmikCnBKsMHn8asUUAeT6xpFxot6be5+dGBMUwHEi/0I7iuD0j/AJAlj/17x/8AoIr6I1TS7bV7B7W8TKtyrD7yN2ZT2NedW3weu7W1it4/EUJWJAiltOOSAMc/va4K2Gk/gPrsuzqlBf7Rulv3Oc0b/kGL/wBdJP8A0Y1Z11/yFrv/AHl/9AFbcFi2medYvMszW9xLG0iptDESNzjJx9MmsS6/5C13/vL/AOgCuSasmme9hpqcoyjs/wDIZRRTTIgkEZdQ7AkLnkgdTj8RWB6oSf6tvoa938Nf8inpH/XlD/6AK8Ik/wBW30Ne7+Gv+RT0j/ryh/8AQBXoYL7R8fxN/wAuvn+hp0UUV6J8cFFFFABRRRQAVFdf8ec3/XNv5VLQRkYPIoA/O+T/AFr/AO8ajXp+Jr3z43/Bb+yzP4p8I2wFjy97ZRj/AFHrIg/u+o7duOngi9PxNfeYXEQxEYyh2/yOWSaEXq31/pR/y0P0FC9W+v8ASgf6w/QVsunq/wBQFwPSjA9KWitrIQmB6V9vfB7/AJI/4b/68x/6Ea+Iq+3fg9/yR/w3/wBeY/8AQjXz+eJezh6s1p7na0UUV8ubBRRRQAUUUUAFFFFAHA/Gb/kn7f8AX3F/M1886j/yDbj/AK5mvpX4naLfa74JmttMi86eOVJvLB5YL1A9T7V81akCNOuAQQQhyCOlfP5kn9Yg+n/BPpMqkvq049bv8idv9W30qKJBJZxA8EIpBHUHFSt/q2+lMt/+PWL/AHB/KvH6Ht9SvHPfSKxSG3Kh2UFpWBOCRnG046U7fqH/ADwtv+/7f/EU+z/1Df8AXWT/ANDarFVJpNqxEYtxTuUXGoO8beTbDY27/XNzwR/c966vwF4w1zwv4itxFFbvZ3k0cVxB57EMGYKGHy8MM/0rCqxpv/IZ0/8A6/If/Ri1th6rjVi4q2pjiKKlRkpO+h9Z0UUV9gfEhRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRXNL43tJWl+zaZqlwkc0kJkjtwVZkco2Mt/eUinf8JlF/0BdX/8B1/+KrhlmGDhJxlWimv7y/zK5Jdjo6KwbLxZbXmpW9k9hqFrJcFlja4hCqSFLEZBPZTW9XTSrU60eelJSXdO4mmtwooorUQUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQBxMfhXxFZX2oNp2oaZ9nu7yW6VZ7eQuu85wSHAOKl/sPxb/wA/+i/+Asv/AMXXY0UDuzjv7D8W/wDP/ov/AICy/wDxdU4/Bmtw6g1/EPDiXjZ3XC2EgkOevzb8813tFAXZx39h+Lf+f/Rf/AWX/wCLo/sPxb/z/wCi/wDgLL/8XXY0UBdmL4V0a40LRWtb2eKeeS5nuHeFCq5kkZ8AEk8bsda2qKKBBRRRQAUUUUAFFFFABXFWiAIuK7WuTtIRHGBnNNCZZiSuW+IOntN4bupI2wyRtjmuvjT5sisfxen/ABTtyWUMgXLZ7e9KexUVdo8p+Gq+bpMcjph1+XPrXqFmzouF4zXnuhmTSdBtFtfLVnQHe/vzVq58S6vZTIsptpkbGBCTuH4V50/iuenTtax3ExleQ4JyetZWows0Z3CqFxrdzBpou3icAjIzWJFr+sakruJLa3hHaQEtWe5o7I4zxvpajXbB41IVplV8DrkivdtIslt9OXauAwGAP4RjpXjOvzSXMcEzFZHhuI2yo4OGFe72CFrGEuNrmNSwHriu+l8J5db4rlW8i+Q9a8a8X4Pie89mA/8AHRXuFygZCK8L8XSAeKr8ekuP0ruw/wAZ5mL+As6KuNM4HVzWha8eZuHpVXRGA0dT6s1RXusQadIFn3bpASoRC2cfSuuTPPjHYnuryG1yZnSMN0LNjNP0W2SW7+3w3SXQlG37O4BVMHGQQM9v1qtpclrrU8hn0z7QIlDKLmIqBn03CuisoY4ljSGBLZQeI06Dms7Obt0NE+RX6ntlFFUtU1W30e0FxdpcOjOEC21s8zEnP8KAnHHXpXAe2XaK5yXx74fitrGYXFxML8S+QkFnNK58sgSAoqllKkgEEDBrY0zVLLWbFLzTbhZ4GJXcuRgg4KkHkEHgg8igC3RTRIhLAMpK/e56fWjzY/LD712EZDZ4oA53xR4YGqIbywVVvkHI6CYDsff0P4fTx66BGsXqsrKyuoZWGCpCjII7GvoQMD0IPGetZF/4S8O6teNeajothd3DgBppYFZmAGByR6VzVqCqbaHs5fms8HpJcyPD6gubYXChlOyVOY5OeD15xjIyBkd69u/4QHwl/wBC3pf/AICp/hR/wgPhL/oW9L/8BU/wrn+ptfaPZfEsGrOl+P8AwDwddWtx5tteTxQ3US/OhcDIOcH8cZx1Ga9y8O+JtCj8L6UkmtaejrZwhla6QEHYODzXmmuaBZ2nijXYdHtobMQ3SCOKJQiEG3hJGB7knPqfrWQrZyCCrKcMp6qfSojP6vJq1zpq4X+2KVObly2v0vv812PdP+Ep8P8A/Qc07/wLT/Gk/wCEq8Pjrrmnf+Baf414bUF7/wAg+4/65N/KtPrv905Xw0kr+1/D/gn0cjrIivGwZWGVYHII9aWvOfCPiY6VFDY375sWAEcjH/UHHQ/7P8vp07+4vrS0jR7u6hgRzhWlkChvpnrXbCamro+XxOGnhp8k/wDhyeioJb+0glSOe6hjkcZRHkALD2B61M7rHGzyMFRRlmY4AHrVnMLRUX2mDbEfOjxNxEd4+fjPHrx6VLQAhAZSGAIPBB7153c/AX4dXV1LcSaAVeVy7CO8mRQSc8KHAA9hXotFXCpODvB29Atc+LPjH4E/4Qfx7dQ6dpslnolwEawZpDIrjy13/MSTnfu4PPTtivPh/rD9BX314s8J6V408PzaRrduJYZOUcAb4X7Op7Ef4joa+NPGHw213wl4qutK+yzagkWDHcWsTOrqeRkDO046qf5YNfT5fj4VIRp1HaS/HcwlG2qOSpCcda0/+Ec1z/oDaj/4CSf4Un/COa2f+YLqH/gJJ/hXsutTtpJfeZ2ZnV9u/B7/AJI/4b/68x/6Ea+Jrqzu9PmEN9az27ldwWaMoSPXBr6Z+HXxu8E+Hfh3o2k6pfXEd5aW4jlRbV2AOT3Awa8XNlKvTh7NX1e2prDR6nutFeX/APDRHw8/6CV1/wCAUn+FH/DRHw8/6CV1/wCAUn+FfP8A1XEfyP7ma8yPUKKy/DniTSvFmiQ6toN0t1aS5AYDBUjqrA8g+xrUrnaadmMKKKKQBRRRQAV5L8Wvho2p6fd6z4bti14Yybi0iXJn/wBpQP4vUd/r19aorOpSjVjyyRrSqzpS5oM+VH8N+IBE2fDusgYPJ06b/wCJrLt/+PWL/cH8q+vnUOjI3Rhg184+OvAlx4Nv1MO6bTJji3mPJX/Yb39+/wCdeBjMAqMOandrqfRYLMXXqctSyfQ4uz/1Df8AXWT/ANDarFV7P/UN/wBdZP8A0NqsV5UviZ7EPhQVY03/AJDOn/8AX5D/AOjFrPlkkhl3t88LYBAHKHpngc9efTFX9MYNq+nMpBBu4CCD1/eLWlFWqRfmjKs06U15M+tKKKK+0PhQooooAKKKKACiiigAooooAKKKKACiiigDhfC3/IHm/wCwjff+lctbNY3hb/kDzf8AYRvv/SuWtmv5/wA0/wB/r/45fmz1afwIpTf8jNoH/X1L/wCk8tddXIzf8jNoH/X1L/6Ty111fqfCH/IrXqzhxHxhRRRX1pgFFFFABRRRQAUUVm+JL6bTPC+qX1qQJ7a0lljLDIDKpI4+opN2VxpXdjSorw3/AIWX4p/5/of/AAHSrWlfEbxLca7ptvPdwvFcXsEMi/Z1GVeRVPP0JryoZthZyUU3d+R79Th7HU4OckrJX37HtFFFFesfPhRRRQAUUUUAFFFFABRRRQAUUUUAFFcz4+8UXPhHwyNSsreK4lM6RBJSQvOeePpXmn/C8dd/6BWnf99P/jXNVxVGjLlm7M6qOErV481ON18j3GivLvBHxS1TxP4sg0q90+zhiljdt8LNuBVc969RrWnVhVjzQd0ZVaU6MuSaswooorQyCiiigAooooAKKpazqS6Pod9qTxmVbO3ecxqcFgqk4z+Feef8LlP/AEL7f+Bg/wDiKwrYilRt7SVrnVh8HiMTf2MHK29j1CivM7b4wia8t4H0JkWaZItwuwdu5gucbeetemU6VenWV6buTiMLWw0lGtFxb7hRRRWxzhRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAVzcY4FdJXNxk4HoehqkItRCoNStFu7GSJ+jcGp4vvcU6aMyW7orbSwIBz096HsUtGee2Gn2cumjT72JWMeYzkZ6HFQQeDtJ0m4kv4oI1bO7JHenzNPDrE7SqUZpTkVbuJhcxeVJLsJHy89/WvMqJxdj16NpRTG6gUOmxjnYjbiCO1Ytx4Q03VJoruWCM7RlXAweeT9aZe6fr62oii1ZJIu7MgGfar0V01npSRtKruq4JU96hXWzNJcrKL6TayanY6bZxrtEqluOwOf6V6yEwg4xxXDeCLJbmC51GePdM0u2EkZxjv+Z/Su7OdvNd9KNonj1pJy0K1wpKnFfNfjPULpfGOqBLC6kUXLgMsZIPNfS8nCmvJ2M1z4muEa4k8syucDHqfau2gpN+6ediZQSXMcdo2tzjS44Rpd80gzkLCfWum0A3lx9oeW2ktCpXb58QyevTmtr7PKoOy5kH/AHz/AIU61WQeZ5srSdMbgOPyrpUJt2nscLnBK8HqMiE+5xNIrDHG1MYp0Zw68/xf1p33WaoN/wC+X6itlFRVkYuTlK7PaqzNfMh0t4o7S/uRMdjf2fMsUqDruDFlx0xwc81p1U1R9RTT3bRobaa7yNiXUrRoRnnLKCentXkH0J59pGha7ot54cvJNInuUsv7RV4o5YjMizSI0RkYsAzkA7mBOTnOetdX4Z0zULWx1We+iWzudSvZbpYFcP5AKqigkcE4QMccZJ5PWq/2rx7/ANAnw/8A+DCb/wCNUfavHv8A0CfD/wD4MJv/AI1QBgQeFpF8GfYYvDAg1BTa/wBpviEHVFSVWmXzA2X3gMfnxndg9TUdr4Hmu9Sthd6LFDoQ1qS6j0yXYUt4TaGPlASuGly20Z+9n1ro/tXj3/oE+H//AAYTf/GqPtXj3/oE+H//AAYTf/GqAOduvCmu2GlWcfh+zjjnmFzpVx+8C/Z7N52aKQc8+WhO1Rz8+K9GtbaGys4bW1QRwwoI40HRVAwB+VcP4jvPFy6DcHV7TRrS1+XdNBq1zHIDuG3aUi3ZJwMDr0wc4qx8N7zxrd6fcN41tYYoNw+wyMcXMif9NVCqB2xwp9VFAHa0UUUAeR63/wAjt4h/6+4//SaGuP1e2juPEcgk34FrGQFkZeSz88EegrsNb/5HbxD/ANfcf/pNDXKah/yMkv8A16Rf+hyV5Vb4pH3+WpOlRT/rRlP+zLb/AKbf9/3/AMaRtLtWUqwlIIwQZ35/WrlFcnMz3/Zw7IgFmgGBJcAf9fMn/wAVXeW8mnS/CrSotTv9MtrkpOlvPq9p9qXaHZSihiOcbQBnPHQ1xVewfDf/AJJ/p31l/wDRr134Ntydz5TiOEI0qfKras43T49Bj1HSx4u02JYf+EYtY4rfUIPPcMHfKAFclsY4Az04rcgtryP4EanBdQ3KSHTL7yIbgEzJCfNMKMDzuEZQYPPGK3dRv/F0WoSppeg6Xc2gP7uWbVHidhjuohbHOe5qt/afjr/oWdG/8HL/APyPXonxhyI0DVrbXfD0V7Zqml6NqEcemOjZLrKJGOVH3RGoSMZ9WqXSvFN7ceJHWe+uIdOubC7luFE5mlsmRk25HlARuAW+TLZ98ZPU/wBp+Ov+hZ0b/wAHL/8AyPR/afjr/oWdG/8ABy//AMj0Aco3iPxBH4beXXr+602/Oo2EMgSBV8u2d1HmDgjc4Lluu0gj+HJni1y7ZlivNbuofDv9pTRQ6uGUNLGIUZAZcY2+YZVD8Z2KMnPO3fP4x1GOJLzwro0iwzJOg/tuQYdG3KeIOxFctqXiXx9a+Mkg0LTrG8upHUXulpqbXEUS4HzljCvkHHPLYPZSaAJJfEWtnSY5dX1S90+caSZ9P2QhGvbnzJAoZSvzMUER8sY++Tj07TwqJv7W8RPcxmN5L6JiO2fssOcevORXRRlzEplUK5UblByAe4zTqACiiigD5V/agGfiNp3/AGDE/wDRkleK7gPvHFe1/tQf8lH07/sGJ/6MkrxX+MfSvtsvusJBr+tTnn8Qm9f7w/Ojev8AeH506ivQtPuvu/4JB2Xwy+Jd/wDDrXhc27efp85C3loW4kX+8PRh2P4V9neH/EGm+KNDttX0W5W5tLhcq6nkHupHYg8EV+f9fX/7Of8AyR61/wCvuf8A9Cr5zOMNGMVW63sa030Ol8Xi2l8S+G7fUbhobOSS5Mg+0NCrERZGSCOhrm9K1rVzqMWlaHqhbS7rXprS0vpx9pY262nmsEdj8+JVZQxJ6Ec4xXf67DbPp/m3WinWTEwKW6xRO+TxkeYQo/OspdfuFEIXwNrQEH+qAWz/AHfGPl/f8cEjivnDYwIvGGsR3VjM9/bTi+v72yfTxCA9qsCSlXJBznMS7s8fvBgDgnPtfHuuQeGbDUH1Cz1KXUdDF++yEKthJviUs205KDzWJBwf3Tc9cdQ+pb5riceAdYjuLmMxy3CR2YkZSMYLefk1X0SWLw/pMOn6d4C1pY47dLd3KWW+ZUXaC5Ew3HA70AVovFuo2Ovvpl1qFve20Oo2kDX/AJaoCs0UhMZx8oYMqYI7SKPc17XxBfa14u0qRNZFtafbNTth5QXy5xFIgQHPBOA3P1IrYXUI009rBPh3qa2bnLWwhshGx9SvnYqtquo3Euivb2fg3U7AxMJYpZLaxkjhYHO7YZwPXnIPPBFAHc1V1LTbTV9NmsNQhWa2nXa6N39/Yg8g9jXL/D3xtfeMbe8N/ok1iLVwqXisrW90PWNgx/EAsB/eNdlRuCdtUeMv8BJ45pRaeIo1gaV3jWWyLMqliQCQ4BPPXApP+FEX3/QyW/8A4AN/8cr2eiuR4LDt35TtWPxKVlM8Y/4UPfHr4kt//ABv/jleRraT6RqkkX22Qvb3R8twqhdyPwACDgZXgV9h18maqofWNQVhkG7mz/38avNx9KnQhF01bU9PLq1TETkqrvodL/wtLxn/ANBo/wDgLD/8RR/wtLxn/wBBo/8AgLD/APEVwscty8k0cYjKxPs3OTk8A9h71Lm8/uwf99H/AArzvrOIX2/xPTWFwz/5d/gdlJ8WfGdt5cv9rLKBKmUe2iwwLAEHCg9PQ17n4S8WWPi7SBd2Z8uZMLcW5bLRN/UHse9fK08d5NGFIgGGVvvHsQfT2rV0PxJrXhXUl1TTjCHiBLxlm2yp1Knjof0612YXHThJKo7pnFi8vpzi3SjZo+sq5r4i3VxY/DXxBc2M0kFxFYytHLE5RkYLwQRyD71vWVx9r0+3uSu0zRLJtznGRnFZviDV9Ksofses2t3dQ3SENHDpk92jL0Iby0YD6Gvoj5k5PbqGjT+GVu1u7ET6y4mSXVZLzzIxZTtyzdsqDt6ZUGqNz4z8Q3nh/VliureN5dFk1OwvFsmhKopA+55zEghgQx24IOQeldTN4x8PXLwvcWOrytA++Iv4evT5bbSuR+54OGI+hNUrXV/Bdksi2mhX0KyxmJwnhm8AaM9UP7j7vHTpQBUuNZ8R6L4l1y4v9Qtb200vRI72S1htGj81szn5CZG2E7FyTuyAOlCeKfFtvpkkt5ZWrNNJaLbXLW5iizNMsbIVEjFsBgQwIz6Vfj17whC8LxaNqCNAhjiYeGrwFFOcqP3PQ5PHuaZa6z4NskZLTRNQhVmRiqeG7wDKHcv/ACx7HkelAGv4X1XUL2bV7DV2t5brS7wW5nt4zGkqtFHKDtLMVI8zHU9M98Vv1wGs/ECz0ZX1DSNKvZomYy36y6LewSOAoG8OYdpIVQMNgYA+YYrq/DXiGz8VeHbTWdNSdLa6Usi3ERjcYJHIP069D2oA1KKKKAOF8Lf8geb/ALCN9/6Vy1s1jeFv+QPN/wBhG+/9K5a2a/n/ADT/AH+v/jl+bPVp/AilN/yM2gf9fUv/AKTy111cjN/yM2gf9fUv/pPLXXV+p8If8iterOHEfGFYem+M9B1W7jtrO+PmzFlhEsEkQmIzkIXUB+h+6T0rcPQ15naaTrOqeFdD8Ptot1ZPYahBcz3ty0YjRYpvMOzDlmZgNo4A+Y5NfWmB6ZmjNeRWHhfxAhvlu4r0aktveh5o4FCXZkVwmZvNJYZKlRtBUgD5QDWlceFLqztJILW0vYrabR7YXH2ULK73McoOWVmAc4yGyfmXI54oA9LyKK8ovtH8Q3VjpMlzpSxWECXMb2dtYq/zM6+XKbcygKSobozFSe2Tj0Pw7GbPQrDTrm6knu7e0jEv2hl87pjLgMeeDzkjIPJoA1KxPGf/ACIuuf8AYPn/APQDW3WJ4z/5EXXP+wfP/wCgGpl8LLh8SPn6rmif8jNo3/YStf8A0clU6uaJ/wAjNo3/AGErX/0clfnmG/jw9V+Z+xY3/dan+F/kfSFFFFfop+NBWXrfiGx0Bbb7ctzI91IY4Y7W2knd2CljhUBPABP4VqVzviW2vjrGg6hY6fNfpY3MrzRwPGrhWgdARvZQeWHegDT0rW7DWrNrnT596I5jkV0aN4nHVXRgGU+xAq8HUtgMCcZwD2rz2TwfqGraz/aOrafCIbzWoruayeRXEcMdq8QL9mJbGVGRjHXFNg8K31vr1u8WjrBLBq011JqyvGBJalXCQgA7+AyJtKhQEyDwKAPRA6sSFYEjrg9KFdWGVYEZxkGvHfC/hrUtS8Cac2jaWNKmk0CWGW882MfbXkCFOVJbsx3MAVzgVt/8I3qcd3d6hpWgHTbQTWEkWkpJCjSNDIzSuArmMEqygZYZ2c44oA7+fULW1ura2nmVJrpmSFT/ABlVLEfkCas15xJoVy+pW2ra3ocUi/23NOtrNJA7iOSARpgs23O5QSobtxnAr0egAooooA8++NP/ACIKf9fsX8mrwWvevjT/AMiCn/X7F/Jq8Fr5vNf4y9P1Z9Rk/wDAfr+iOz+Ev/JSrH/rlN/6Aa+iK+d/hL/yUqx/65Tf+gGvoivSyz/d/mzy81/3l+iMnUfFGiaReG11PUYbWZYxIwkJARCSAzN0UcHkntWpHKk0SSwuskbqGV1OQwPQg9xXIX19caR481Gc6LqWoRXmn20URtLcOjMrzblZiQq/fXqR1ri5PC/iDSrHTbHUFuPsqaUsEP2K2mu/slwZJGbb5cqFSFaMK5BHyHkd/SPLPZaK83u9A1T7RqupBL6XUU1uwNrKHcZgCWyylUB2hT++3Y9DnpVE2GvY1200O0vHkmhnf7fdW8lvMC0yt5IYvtlyhcKybdoUDIzmgD1aiuL8DI1hFqd1dyz21o7RbYbmxks44mAIYqJZHPPy5OQMjjOTXaA5GRyKAMLxv/yIOvf9g6f/ANFmvn+voDxv/wAiDr3/AGDp/wD0Wa+f6+Yz7en8/wBD7rhPat/27+pNZ/8AIUsP+vyD/wBGrX0vXzRZ/wDIUsP+vyD/ANGrX0vW+RfwZev6HHxV/vNP/D+rCqep6tYaPai41O6jtomcIpc8ux6Ko6kn0HNXK5vxra2s9hZT3KaqstrdCW3uNKh82W3k2Mu/ZtbIwzKQVYfN0719AfIm5Y31tqVml3YzLPBJna69DgkEfUEEY9qqXviLSdO1JbC9vY4bhoxIVYHCKSQGdsYQEggbiMkYGTXAM2t3lvp914vsdWvtPWO7jjW1t3jndy6+RLLFEQVYoHA7KSCdpPGTc+CtbvdN1KTWtPnu9VOgaYskgckzTxyyNMoIOGbaF+pI9aAPXV1WwbV30tbuE38cIne23jeIycBsemRjNGmarYazYi80m7hvLZmZRLC4ZSVOCMj0IIrzm78L6jqniy51Pw9by6eDpttbQyXivEfKfz1lXkE7l3RuAe6qDjOazItD1LTNDt9Hj0W5S0N/qhjkS3mlaPNz+5UKkibQykkSMcLjtnNAHslFeWyW3iW4Xw9cyW+qeRb6daHxBEGZXumwp2ouMlkbcX2kZU7eTwPUhQBTuNX020mMN1qFrBKOqSTqrD8Caj/4SDRv+gvY/wDgSn+NeaeJzZ2Or+LdUn0mz1GeG5tUjW5jU/ejiXG4gkD5s1DIbPTZ5rbXvDGi2sps5rq2mgQSxSCIAuGHlhlI3A8A5GccjFBVj1H/AISDRv8AoL2P/gSn+NH/AAkGjf8AQXsf/AlP8a89hPhWbUksE0OCWfCCSSHSi0UTMoYBnCYXhgeexGetQ22oeCbu8S3h0u1DS+YYHfTNqThAS7IxTDAY6jjp6ikHKekf8JBo3/QXsf8AwJT/ABo/4SDRv+gvY/8AgSn+NefTS+C7e1guZ7DT44Z7J79HNivMKBCzfd/6aLx156Vm6hq/hmyTTZF8JsyXt79lKvo7I6fu2fcEMeW+6Bge/oaA5T121vLa9jMlncRXCA4LROHAPpkVNXGfD23gtbrxNFZwJbwjU0KxxoEC5tYD0HSuzpkhRRRQAUUUUAFFFFABXMwKdv8Aq2rpq5+JwFzVREyVN277pqQbscqay9T8UaPoozqWoQQNjIQv8x/CuZ1f4r6fa2xbTYHnYj5Xl+VT+HU/p9aYGj4yS3iNqVVBdSMdq5wXAHP8xXNW5g1FijojsPlIccrXnGt/EDU9T8S2OpXWMICFT7qom45/lXbmKLW9Ng1nRpzbyzRhw69H/wB4VxYmFmmd+FqWWhfvPDcO3czW5X0VMEflXP397aabE8cQCqqksFOcAdTWXf6p4hikMF1IYl6bwOGHtXPa5dbdDu4rd/MneMg5YbmJrGEW33N61W6Ppbw/a21voVmunsJLdog6yD+PPOfxzWi6tg8V8daT438S+HpYrew1e4gj8sM0ay5VSe23kV6bpvxn160sk+1fZ784GfNTYxH1HFenyNHjt9z3CZW8snAFeU6afN8RXDnnlz+tdnoHj/RvE+lebBcJBchT5ltK4DKcdvUVwnh6bfqdy3+wf5114XdnnY1/Cb8gHNV0IQt709pOtVi/zGu089Dnfk1SaT9+oJwNw7+9OmlAbrXB6hZeIfHnjGbwz4bhjWTTSl3JK0/llkwoI/N656tTlVzpo0nOVj6uooorzD2zj9elvdO8ZaPPBNdJaXd2sE7m73R8o2I/IPTJAO8cj6U3QfE914pvNY0yZYrYaeDC81tMVa4feyh4j/CnyYzyd24fw5PQr4e0ZNYbVl0qzGosMNdiBfNPGPvYz04+lLN4f0e4tkt59Ks5IEh+zrG1upVY8g7AMfdyqnHsPSgDg7XxfqXhzRdYnvkku207Vltzp8s/nTiJ4kZUil/5atlt+G5ALDsDWvqeoagL7wVe/wBpbf7QvBDcwWrg28qtbTSZGRk8quDnt0Ga6az0HSdOhgisNMtLaO2ZnhWKBVEbMMMwwOCQSCe+arXPhHw5eC3F3oOmzi2BEAktEbygST8uRxySePWgDB8zVtJ8eo2rSNcafqd8YbHyr5v3P7ndtaAqFIyjnIYkEjiu2rOi8P6PBq76rDpdnHqEmd90sCiRs9fmxnmtGgAooooA8l16N4/G2vF0ZRJcxumRjcv2eIZHqMqR9Qa5LUP+Rkl/69Iv/Q5K9v8AEPh+HXLTgiK7iB8mbHT/AGT6qa8T1iGa08W3NvdxmGaO1iDo3+/JyD3HvXnYim1eXc+0ybFwqqFLaUf8mR0Um4eo/OjcPUfnXnn1otewfDf/AJJ/p31l/wDRr149uHqPzr2D4b/8k/076y/+jXrvwXxM+U4l/hU/VnQaktu+mXCXkvkwPGVeTzjFtB4++CCv1BzXnGl65feG9E1prXZeTWepRJFp0d5JeLKHRcwxSv8ANvOS2CMA9sc16dJGksbRyorowwysMgj6VFDZWttGkdvbQxJGcoscYUKfUAdK9I+JPOfFV/8A2h4KtNa/tG1/tGO0+0s9vqk1r5KnJ3RxAgSsCCoWQDcVwccitv8A4Su9/wCE+j0PdbixYLIbt0YFW8vd9mP8PmEfvOv3c8dDXVPp1lLJHJJZ27vGSUZolJUk5JBxxUn2eE9Yk5bf90fe9fr70AcJ4VdbL4i3un2100lpPYm4hSLUZL1HAlAEkjSEmJyGwFXIYbuTtFd8qKrMVUAscsQOtRW1la2e/wCyW0MG87n8qMLuPqcdamoAKKKKACiiigD5W/ag/wCSj6d/2DE/9GSV4r/GPpXvf7UGg6kfEena8tqzab9kW1adeQkgd2wfTIPFeCfxj6V9rlzTwcLf1qc8/iFooor1CAr6/wD2c/8Akj1r/wBfc/8A6FXyBX1/+zn/AMketf8Ar7n/APQq8PO/93j6/ozSnuep0UUV8kbhRRRQAVBeWVrqNq1tf28VzA5BaKZAytg5GQeOoqeigBERY0CRqFVRgKowAKWiigAooooAK+TdT/5DV/8A9fc3/oxq+sq+TdT/AOQ1f/8AX3N/6MavGzb+HH1Pbyb+LL0Muz/4+Lz/AK7f+yLVuqln/wAfF5/12/8AZFq3XgT3+4+jp/D9/wCYVDd/8eU//XNv5VNUN3/x5T/9c2/lSj8SHL4WfWmjf8gGw/69o/8A0EVdqlo3/IBsP+vaP/0EVdr7k+ACiiigAooooAztT0DTdZurabVLf7V9lJaOKR2MW4/xNHnaxHYkHHatAAKoCgAAYAHalooAKKKKAOF8Lf8AIHm/7CN9/wClctbNY3hb/kDzf9hG+/8ASuWtmv5/zT/f6/8Ajl+bPVp/AilN/wAjNoH/AF9S/wDpPLXXVyM3/IzaB/19S/8ApPLXXV+p8If8iterOHEfGYeq6Lq99fGaw8UXumwlQBbw21u6g+uXQnn61S/4RnxF/wBD1qf/AIBWn/xqupor60wOW/4RnxF/0PWp/wDgFaf/ABqj/hGfEX/Q9an/AOAVp/8AGq6migDlv+EZ8Rf9D1qf/gFaf/Gq5LxR4E8VazrFtDYeIb8XEO2T+2ZYLWHyBn7qGOMSOfVSVXnk9q9WooAr2EE9rp1vBd3TXk8carJcOgUysByxC8DPXArM8Z/8iLrn/YPn/wDQDW3WJ4z/AORF1z/sHz/+gGpl8LLh8SPn6rmif8jNo3/YStf/AEclU6uaJ/yM2jf9hK1/9HJX55hv48PVfmfsWN/3Wp/hf5H0hRRRX6KfjQVR1eyvL+yEOn6pNpcocMZ4Io5GI5+XDqwx+GeKvUUAct/wjPiL/oetT/8AAK0/+NUf8Ix4i/6HrU//AACtP/jVdTRQByq+FvECKFTxzqSqBgAWNoAP/IVL/wAIz4i/6HrU/wDwCtP/AI1XU0UAcD4k8L+IJNGkibxBqet+awQWhsbHaxPdi8eAo7nkjsDWj8O/DGt+FtBa08Q69Lq0jNuijfDC1Xn5FfAZxz1IHTgCutooAKKKKAPPvjT/AMiCn/X7F/Jq8Fr3r40/8iCn/X7F/Jq8Fr5vNf4y9P1Z9Rk/8B+v6I7P4S/8lKsf+uU3/oBr3/Uba4vNPlgs76SwmfG25iRHZOQeA4KnI45HevAPhL/yUqx/65Tf+gGvoivSyz/d/mzy81/3l+iOW/4RnxF/0PWp/wDgFaf/ABqj/hGfEX/Q9an/AOAVp/8AGq6mivSPLOW/4RnxF/0PWp/+AVp/8ao/4RnxF/0PWp/+AVp/8arqaKAOK1bw34gTSbgv4q1bUl2YNpHYWLGbP8OHjC/mag+G3g/xB4YW7k1vW5Z7e5O6DSztdLT6MFXH+6oCjPGetd5RQBheN/8AkQde/wCwdP8A+izXz/X0B43/AORB17/sHT/+izXz/XzGfb0/n+h91wntW/7d/Ums/wDkKWH/AF+Qf+jVr6Xr5os/+QpYf9fkH/o1a+l63yL+DL1/Q4+Kv95p/wCH9WFY19F4na8kOm3ukx23GxbizldxxzkiUA857Vs0V9AfInPeR4y/6COhf+AE3/x6jyPGX/QR0L/wAm/+PV0NFAHPeR4y/wCgjoX/AIATf/HqPI8Zf9BHQv8AwAm/+PV0NFAHlWuWXjpvFat4XurVdUJT7XKtpPHZFBjiTfKyscdDGpb1IFepReYIU88qZdo3lBgE98e1PooA8w1vSH13VfF2nwzrbvJdWrLIybwCsUTcjIz931pbzwvfavJcT6xqMMkpsZ7O2S3tikcPmgBnOWJY8L3AwPeui1LwIb7XLzU7PxJq+mNeFGlhtRblCVUKD88THoB3qv8A8K/vf+h38Qf98Wn/AMYpFXRhXHhCebXLO9iube1FsY981vG6TTIqgGNyH2spx3BwOB61kaXpGpya9o2nyC4fS9HhnhEktp5PyFPLRSxY72weqgDAJPJFdp/wr+9/6HfxB/3xaf8Axij/AIV/e/8AQ7+IP++LT/4xQF0c5Z+D9RiNn9tv7G6jsdMk02GJ7MlJFby/mkBfniIAgYHNR23ga7t4oXi1GKKS21Bb62gEbvBDiJoygDPuAO8nggA4wK6f/hX97/0O/iD/AL4tP/jFH/Cv73/od/EH/fFp/wDGKAuibwNn+0fFG7Gf7TTOP+vWCuurE8M+Gk8NQXijUbzUZby4+0TT3fl7y2xUA+RVGMIO1bdMkKKKKACiiigAooooAK+TdT+I2q6/rOxbtobdXbEIYopGOP8AJr6yr4NuZzbXcCwMvAII2+nf9a1ppO5EmdOLuOXWCt1mZ5VKkl847YFS6jqsMN5FZQDyoIkxt7sfU1zFtqEz6hFJK2cNkqOgqprOoCbxDM5Py761sQjR1C9KRuY3yyHGMAgqeeh68j9a7j4d/EiG3jttG1G3jSHIWOVONmT3H1NeR3V29xMz9B/CBxSw300cqSJJ82fvFQxFZ1YRmrM2pylB3R9C/E/VU0vwnJJblZHuPkjdTntkkH/PWvnmW4eRiZJNwI6E5rqvEF/PfeHrKCeZnEK8At1LYJbHvgVx4VVkyxziscPDlgaVqnPK5YgfynGT1HStu1umeEhW5HAxXNu4PSr9mkgt0kUkKTwSwHP+fauptI5mrm1Y30lvJvRyrE8EHmu28NeLmsrsPcjMRG2VvQZ615gt4V3Bzzng460S6pIyPGhxk8kelOLs7oynDmVmfS4nWRA6MGVhkEHrWde6pa2koW5uI4iwyN7YzXE+CfGlgnhiC31W9jhmhJjUSNjKjp/PFbsvw8HxgBl0TXbSFdO+WTKF8l+R06fdNbTrJLR6nDDDtzsyp4m0bxH4wigj8CZuprdi1wLe5RCqkYGcsO+a9n+E3hq80DwJYDxDYRwa9iRbqYhGlYGVioZ1zkbdvfsKw/hB8Ib34aalqVze6rBfLexJGqxRsu3aSc8/WvVa4JScndnqU6ahGyCiiipNAooooAKKKKACiiigAooooAKz9Q0DR9WmWXVNLs7yRF2q9xArkDrgEjpWhRQBif8ACF+F/wDoXdL/APAOP/Cj/hC/C/8A0Lul/wDgHH/hW3RQO7MT/hC/C/8A0Lul/wDgHH/hWra2lvY2qW1lBHbwRjCRRIFVR7AdKmooEFFFFABRRRQAUUUUAFFFFABRRRQBV1PTLLWdMn0/VLaO5tLhCksUgyGFfInxL+DGteEPEYGh2V3qmlXO5reSCJpHj5+44UcEevf86+xaK68Ni6mGleG3YmUUz4I/4QvxR/0Lerf+AMn/AMTR/wAIX4o/6FvVv/AGT/4mvveivT/tuv8Ayr8f8yPZo+CP+EL8Uf8AQt6t/wCAMn/xNfVnwB0+80z4T21tqVpPaTi6mJinjKMAW4ODzXpdFceLzGpioKEklrcqMFF3CiiivNLCiiigAooooAKKKKACiiigArwn4l/DyTQ7mXWdJR5NOmcvMnLGB2OSf90k9e3T0r3amyxRzwvFMiyRupV0YZDA9QRXPiMPGvDkkdOGxE8PU54nx5Z/8fF5/wBdv/ZFq1XsN98CLWTVLu40zWXs7a4l8xLdrfzPL4AwG3Akcd6h/wCFDt/0Mf8A5Jf/AGdeFPLa7elj6GGaYdR1v9x5JUN3/wAeU/8A1zb+Vew/8KHb/oY//JL/AOzpsnwEMsTxt4kOGUqcWQ7/APA6lZbiE76feOWa4Zq2v3Hqujf8gGw/69o//QRV2obO3FpYwWwbcIY1jDY64GM1NX058oFFFFABRRRQAUUUUAFFFFAHC+Fv+QPN/wBhG+/9K5a2ajPgHRfNleN9Uh82V5WSHVbmNNzsWYhVcAZJJ49aT/hAdI/5+dZ/8HN1/wDHK/NcZwdicRialZVYpSk316u52RxCUUrFeb/kZtA/6+pf/SeWuurBsPBuladqUN9C+oSzwbjH9p1GeZVJUqTtdyM4JGcd63q+wyTLp5bg1h5yTd29PM56k1OV0FFFFe0ZhRRRQAUUUUAFYnjP/kRdc/7B8/8A6Aa26juLeG7tZbe6jWWGZCkkbjIZSMEEelJq6sOLs0z5nq5on/IzaN/2ErX/ANHJXuH/AAgnhX/oAWH/AH5FSQeCvDVtcxXFvodjHNC6yRusIyrA5BHuCM181SyScKkZ860aex9tX4np1aUqapvVNb90blFFFfTHxAUUUUAFFFFABRRRQAUUUUAFFFFAHn3xp/5EFP8Ar9i/k1eC19S+JPDdh4q0n+ztU83yPMWQGJ9rBh05/GuT/wCFK+Ff7+of+BP/ANavJxuCqYiopRa2PZwGPp4am4TT3uec/CX/AJKVY/8AXKb/ANANfRFch4f+Geg+GtZj1PTjdm4jVlXzZtygMMHjFdfXXg6EqFLkkcWNxEcRW547BRRRXWcYUUUUAFFFFAGF43/5EHXv+wdP/wCizXz/AF9I6xpyaxol7psrtGl5A8DOvVQykZH51wH/AApq2/6Dlz/34SvFzTBVcU4ez6X/AEPp8hzPD4BVPbX961rLtc8zs/8AkKWH/X5B/wCjVr6Xrzi3+D9rBeQTtrVy4hmSXb5SDdtYNjP4V6PWuWYSphaco1OrOfPMwo46tGdG9kra+oUUUV6p4AUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFeCyfswwySKzeKWyvTFgP/jle9UU1JrYTSZ4C37LsRIK+LZBj/pwH/wAcqFv2VIGkZz4tkyxz/wAeA/8AjlfQlFVzyCyPnr/hlKD/AKG2T/wAH/xygfspW4Of+Esk6/8APgP/AI5X0LRS5mM8Kk/ZpR7UQHxVJgdD9hGe3+37frVA/spwHP8AxVsnP/TgP/jlfQlFJSa2A+ef+GUYP+htk/8AAAf/AByt3Tv2cdKsbaNZtSjuZ4xgTvZ4P5b8V7TRRzMVkzwjVv2YrTU7pZk8SSW+F2lRZ7s89cmSqbfsqW5bI8WSDj/nwH/xyvoOinzMLI+ez+ynbsuD4tk9v9AH/wAcr0T4V/CyP4Y2+pxR6q2o/b3jYloPL2bAw/vHOd36V6BRSbb3HsFFFFIAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACivPPEWmW2sfEueDUBLJFDpUDoizOgVjLKCcKRzwPyrHlsvCcOjtqT2919nW6+yEieXPmed5PTd03d/Sgdj1uivNl8LeG2uTbqpMyjJjF7JuA+m/NEfhfw3LMYol3yAZKLeyEgeuN9A+U9JorzRfDPhl9+z5vLAL4vpDtB6E/PxU3/AAh+g79nkSbsZ2/a5c49fvUBynotFcH4IsYdM8c+IbOz8xbcWFhII3lZwGL3QJG4nGQo/IV3lBIUUUUAFFFFABRRRQAUUUUAFU9X1OHRdGvNTu1kaCzhaeURrubaoycDvwKuUyWJJ4XimQPHIpV1YZDA8EGgDBj8a6XPqL2NslzNOt0bZVSMfvG8ppNyknlcIy5/vAiqVx4/s5tKe90WGe8WG6tbeYeUfleWVUaIDIPmKG5HQEjPepNI+H+m6JNazWV3e+da2L2cckkisTudn8w/LguC74PTDHiprHwNpemwtDZSXMULzwXUkfmAh54nD+aSRnc5Vdx74z15oAa3j3SYNOjvb6K7s42mlt3E0QzFOn/LJtpI3N/DjIboDkgGrrnjo6f5cVlpl28v2uztp5ZYx5Vu00kYMbENneEkzwCASMnmrd54E0vUBKl5LdSQS3Ut4YfMAUTOABIMDOUxleeCc9QCGXfgaG9uA82r6j5bT211PCpjCzzQFNsjfJkE+WmQCAcdBQB1FFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAcPf/APJU7z/sD2//AKOmrir3wLPL4fleOK8OotrH2kRfb5PK8v7Zv3eXv2fc5xj9a9C1vwrq174nbWNG1m0smktEtZIrnT2uM7XdgwIlTH3zxz0qv/wjPi7/AKGbR/8AwSSf/JVIpNWOFk0fxBceNLW7exnjFvqxlaWNbdIPsxDKCCP3rMQRuB4zn2qv4IsJ7m20VrfR2tjaX91cTanmPbNGXmXywQd5JLLkEADZ7CvQv+EZ8Xf9DNo//gkk/wDkqkXwt4sRcJ4k0ZR6DQ5B/wC3VA7o878I6Kmo+HtC+16KNP0+LRGjvbqR4wt0ksacAg5I6sSwGCK6D4fx317az61q8kU00oWztpYzkPBCSof/AIG+9/oVro/+EV8V+X5f/CR6Nsxjb/YcmMemPtVKPC/i1VAXxLo4A6AaHJx/5NUBdB4X/wCSjeIv+wbp/wD6Mu67SuZ8M+GdR0fWtT1PV9Vtr+a+gt4AttZNbrGsRlPeR8k+afTpXTUyXuFFFFAgooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigArnovFyXGv6lo1ro+pTXemiNrgAQqu2TcUZS0gDA7G6dMYODxXQ15bBc6d4i+KvjPStO8UHT7yaxsreOSwuY/ODx+f5gUMDkrkBsDK57HkAHoOm6uNSuJI0sbyBY4YpRNPGBG+8H5VIJyy4+bHAyOTWjXjN5r8cXi74lWdj4gWGe30CFbUW85b7PJFFN5nlRhiVKnBKryp5PPNbHgzXdES68UeKE1y0GkW8MLfYbO9kmjsFEeZW8lflG5lJBVMnDdyRQB6dWNpfiez1bxFq+jW8F5FcaSIjM9xbtEkgk3hTGW5YZjYbsYPYmtgHcoIzgjPIxXFaFrel6h8YfE9tY6hbXE8OmWMUkccoZleOW68wYHdTIgb0LAHBNAHbVXv76LTrGS6uPupgBQQC7EgKi5IBZmIUDPJIFN0zU7PWdNh1DTJhcWs4JilAIDjOMjPbjg9+o4q1QBztv4wiuNVu9PGk6gk9i0Qut3k4hEv3CSJDkY5+XNaOh63b69YSXVrFNEIria2kjmADLJFI0bjgkcMpGQea5Dwnruk3nxa8ZW9pqdnPM4swkcc6szlI2D4APO0kA46Hg1w9rrvhyyn0rW4PEFol4fGF9Gz/2kNgtHuLgsfL3bNpV0O/HRlOelAHvFFeV+B9Rl1bWbF9Q1hF8SWkk66lp8ViyTOjOQBOS23aoCMrYHRQpIbDbnxIkhguPC8l5fXFlZyaq0F40V3JAhgNrOzb9rAYBjU7j93BII5NAHcUV4xGul6ZdaTY/27cw6Fe+JLiPTzLqrotxZPp5LhTuBeMXJ2q/JBZdrfOC2lrLWenjxJo19NPa6hbRQp4Xe4m/eShLeMxi3LEmSQXAcP1LZQNkYFAHqtFeF6tDHc3Pi2w1vV76LxElnbS6TbDVpUkN81sWIgQPhj5rDCqCF3cBQa2dV1K7ez8UWeuTtbeLIvLfw8CESWVhbxvGtv/z0HniQPjIwcNxwAD1uivHrjWJLf4mWsS6jbardz38gS2jmVb7T5lspEMbx8iS1OPMGNmHYE7j1b4f1XUL7wveanoeptdeKoNBlj1KxtrFlkjvfKZlM6s2PNWZWQALk7mG3aBsAPUn1qGPxNDojwTrPPaS3cU2F8tljaNWH3twOZU6jHXmqfinxfp3g6zt7zWxLFZTTpA10u3ZEzHA35YEDvkAgAHNcn4fv/Dd/8R9Bu/Cd2L22l0K9R5oneQFxLZtmTPSUg5Ythzld38Nb3ja40KebR9F8Q3dpHHqdzJAbeecI0ytbzIQMkHq6rkd2UdSKANPxR4n07whoM2r6uZPs8RAKwpvdu52r3wAWPoFJ7Vcgv3mvzatYXUO23SdpZFXywWLDy9wY5cbckDIAI55FeI+JLm6tPgxq6eL557KbRbOXQLSOR2VNQl3ALOFPMjGJY8NnAzNwBnFzxZ4reP4ma7J4Q1r7ZczeFEltILW7+0b5/OLN5UeSN/kqHwo6fNjnJAPbqK8b8Xar4WHgbWda8K6/cQQ3UtrGv2e/eC1SZWwyoAQC7xOxdBkERhmAIBOzP/Yui+JILfWLtf8AhDb7TDNZXl/fedbPdvKzSfvpHJDtGUZDnp5hU53UAdfqfiiLTPEFno7adfXF1fJI9sYRHtkCAF+WcYI3DrjOeM1e0zVF1L7Uv2ae1ltZvJlin2bg2xXHKswI2uvevJIdcg0/xB4Ht/F/iBbW8tItT8ybULlIbhYGYC2abONrvEEPzAMTnIzkVpaje6VrGnR6X4b8TReIPEdtex3WlXlxPERPMuHeNjFtV0WNMyBQMKydX20Aer1na1rVtodrDLcrJLJczpbW9vDgyTyseFUEgdAWOSAArE8CvLbrW/Duo+APBmoaFqdzZ6X/AGtHb3wTUZI/JDRu8yTMrAZUgNuPCj5lIUg0w2nhdNF1PR/EF5OvhLUdZUaDqz3oZLOQWqyGSKd2JQCRJQrcgnI5DHIB6ND4uSeV7ddG1QXaXRtjavEiuSI/MLgl9pjwQN+7G4gdSKTT/GVnfJFM9nd2ltLcT2wubkxBBJD5gkU4ckY8mTkjHy9eRWH8PPEGqTWWujxBfWuo6Tpc3+h+JlZEjv4dpZ2bGF/dfdZx8pII6qxrN8N3Nr4u+DviXS/Dl/a3l7ctq6JHFOu5DPcXJhLDOVDAggnGRzQB0Nx8Q7OLw1deIYNG1i70i3RpBdQQIRKinG9ELh2Q9Q23G3nOOav6b4y0rUvFV/4bDvbavYosklpPtDMjDIdcEhhgjOORkZxmsXwZ4x8OXHhDS9Jm1C3/ALSgs1tLnSX5ulkjTbLGYOXOCrZwpGATyOax7zSLLxzfeIrnwprVnB4i0fV1uNPv4HSQwubOFCj4BPlOVdGHQlTwdpFAHU6l48sdF0GXWtZ07ULHTbefyLi4lSM+SfNEW4qrliu84yoOQM9ME6Fz4ltYLzSIYYZruLWGC2l1bFGhY7Gk+9uHGxGbOOQOMniuUHizT5fAthJ4vWDQbrUtQ2yadqUqKcpdDzV+bhkAGd3Qgqe4rLtdH1Lwf8QPDPhuGKa58NPqc95pty2MWP8Aol0GtD3IG/chPbK87c0Aer0VzHxEv7fTvBNzPdzXUERmgQy21wINpaZAN8hB2REkBzg/IW4PSvJP7etoNLurHV/EK2ht/G0X2aOHUGtU/s+V4ZQ6qrj90VZnUnIUZIIxmgD6CrM0bXYdal1KKG3ngk027NnOs4Xl/LSTI2sQRtkX9eK4GB9GsvFd/wCFr641ODUNPurafQY0nczzWywo5jidydyGRbhH3HG07SQFG3DutU8NrqviDXDrdql3aeMLFYZBqO1FicWaSnYG2kFI5wSQcCN+mw4APX4NVSWS7E9vcWaW1ytsstygRZ2YLho+eVJcLnjLAir1eD/27oWoJ4zmutWs9QtLfxTpl1G8t0twsdv9otQ7qSTiMZZePlAyOnFb9rqAvPGFzp95qaafqlpqiyaPZrp7LcSWaxrtRPmVTCwMinIwPmJKlQVAPWabHIksavGwZGGQwPBrzfQNR0vW/EU9pqsl23ifT9TvEuLJRsM9m0jJH5qH5WtxDJC4zjLKCMs2GyPC2qaHp/w8+GurRXFpaWtvcJBqF2AI0jc6fMjCR+AP3vlgk8bgvoKAPYaK8T02bSJm0LTL3U57WO48VarZfZJL6W3MlsRdqibCykjcYkBxkEhQQTitbw7Olx4o/s2TW5Ida0jVZlNl9nle5eyVzHEru74aEwvE+7GN2GJL5JAPTNT1G20fSLzU79zHa2UD3E7hS21EUsxwOTwDwKZpuovqCTmXT7uxeGXyyl0qgt8oYMpVmVlw3UHqCDggisH4pSWsfwm8UG+aFYzpVwqmYgAyGMiMDP8AEXKgd84xzWNqGpaLb+JrNNXm0+HwXdaSfsFyXiSyN0ZCXG8HAcxlSp7jzNpzuoA9EorxzRLeLUfFOgaH4p1nUJbubS7/ADb3GpyQ3EqR3ULWjvGrKVlMClz8qsdrFhlTjr/i7cw2nwq12aW+eylW0k+zyJdNAzS7TtUFWBYk/wAPOfQ0AdpVZbwtqsll9luAscCSm5KgRNuZhsBzksNuSMcArzzXjHi+XwtLF42Ftr4kWPw5b6jaD+2ZCWuiLoLIP3mSxDW4C9Dvj45Wq2r+MWbxpqk/hHXv7Qu5fCUTQxWt59pLXKzHzBGm4jzBEm4qozwWxkk0Ae80V434u1XwsPA+sa14V1+4gguprSNfs988FqkyvhlQAqC7xMxdRkERhmAIBOjnQtO8Qalpms6hJF4fvdOiuNEvJ7tpt8srSmZreZyzNKcxMoUlhwVHzcgHqdFcn4Xl8ayWehnXYNOEDWER1B5JHW7E/lfN8irs+/79M/SuK8M6tpWoaZHqXiLxHGslvYPa+JrYwyW/lyyDDfaGZ/ldZUZIyoGNxVAFxtAPYaK8Nsr210/wb440aa7e38R6Zozz2k8F1sla0WEy27ho8ESKSok5YsQCWZSoE/iH+zbLS/EWq+HtbvFhbw3df2lKmpyBYdQVozbLu3ZSYsZV8sEcbVKgMAwB7XRXl3iK70XRbjSZm1iGPw3rC3dxPeXjy3dtNdEQ+WNwcBcoJ2UZCZUkDcFIxdWv30XWdJt77W/7Xlhl020exvpBBqQK3SlLmAEtvEgIEqkBmC8svRQD2uq2nXh1DTbe8a0uLMzoH8i6ULLHnswBOD7Z47815lbeJtNPjy6hutTsbq0lu7uKa4N0tvf6Z5STLIs23/l2/djZIChBaPO4nced+GXieKXwr4TPizUYZtEayvUuri+kR4kvxcBkWaRvuuYmYqGIyDkZoA94orxuCawOraHpPi/X7iK0l0zVA0d7qj27TWsd3H9jkkAZcMYQ53YDMFbdnBA7T4U6z/bnwx0e5k1AahcRwiG4l80SOHXs567sbSc885PWgDsKK8PsruKXwt4u1rwzrd3qGpaZqkkUMkWpzXhisnkiDNs8w7h5aSENy3yfKcqMalxr+naZaW+sW2sLf+FbvVoE1IWFo0VpbIYZEzkscIZhBvAOOuR87BgD1yivM57q00qXw/Ibq6n8EzzXUlxd6g6tboZFV7UEtgi3G50TI2giP/YJzbnVRoek2dxquoGXwwfEki2X218xXNi1o5Vd+OY1l3mMtwwSPBI2tQB69VS6vzbX1lbC0up/tTshlhjBSDClt0hyMA4wOuSRXjFsulLD8PrLV/Fp1A6jcXIvJE1+do542gnVBzJx822PjHzZXqSKjtfFej/2p4FsYvE9vNbWmtapbSRtqQcfZg08dt5g3fMCgjCs2cgjB+bkA9ol1SNfsxtYZr1Z7prYtbAMsJXdvZySAFUoVPfOAASavV896rq+j6NovhlLHUINNuIvH0seoLFN5ANut7O7CUAgMqqYjznaHXoGGeq1e9up7PxHZXFzJa+OIdRlk0KNSguJogwNt5Q53wFRtk/hH74vtIYgA9aorxS51Lw/b6hrWrL4k/0jTPFtjFayyay7LHDKLRZ1w0hBUqLkHOQBG+MbDj0nx5E998NPEK2KNcTSaVcNbCEb2aTymKFMclt2CMc5xigDoqq3t6bN7VVtLm5NzOIcwICIsgku5JGFG3r6kAAkivJ9Q17S7zxLqN7p+utZ2N34YgDanbjfEkjXPleYSSFO3IVyCGAVhkFeMDWfFcUel+G5X1HT9PkXxrZx3baVqX+gXEKQxNLJEBtHkgmMsG3bHLZbmgD6BorwO28RaJZiLV4fFYe9tvF32aKSfWmmH2BpwjZV5CGTys/OQTgA5+UY6FNQsLv4kQ2F14hgg1az16VnMk8lnNdWjRkx2xjBUviQxBc7ldY94yHKkA9R1PUItK02a9uFldIgMRwoXeRicKqqOrEkAD1NYTeO7KPS9avJtP1CI6C7LqMDJH5kKiIS+Z9/ay7CCNpJ56Vt6tq1hoWlzajq93HZ2cOPMnlOFTcwUZP1IH415brt5bad4H+IFwdfttQ0XV9NkbT9RmkhBubt4Z0eBZEwJtojiC8EjlcnZgAHfzeMLKxvtPtdatrrSm1KUQWb3SoY5pTyI98bMFY9gxG7nGcVuyyxwQvLM6xxxqWd3OAoHJJPYV5n411qw8d+CR4f8GXMes397LajzbIiWOwAkEnmzPyseBG2A3zEjABrf8Q2Pi3WNF8T6W0GlLaXmm3Vvp7wXEnntI6FY94ZQqjk5IJwcUALP8Q7OLw1deIYNG1i70i3R5BdQQIRKinG9ELh2Q9Q23GOc45q/p3jLStR8VX/AIb3vbavYosklpPtDOjDIdMEhhjGe4yMgZrE8F+MfDk/g/StIm1C3/tO3s0tLnSX5ulkiTbKhg++cFWzhSMAnpzWTe6RZeOb7xDceFdas4PEWj6stxYX8DpIYHNnChR8ZPlOVdGHQlTwSpFAHUal48sdF0GbWtZ07UbHTbefyLi4lSM+SfMEW4qrliu49VByORxgnQufEtrBeaRDFDNdxaw4S0urYo0LHy2k+9uHGxGbODkDjJ4rk/8AhLNPl8DWEni9YNButS1ELJp2pSopyl0vmr83DIACd3QqVPcVmW2jal4P+IHhjw3DHNc+Gn1Oe8024bGLE/ZLoNaHuR8+5Ce2V525oA9XoqtY6ha6lDJLZSebHHPJAzbSvzxuUccjnDKRkccVZoAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigClq+mJrOkz2Es9xbrMB+9t32uhBBBGQQeQMhgVIyGBBINPSvDrWF8L7UNVvNYvUiaGO4vEhQxIxUuqiKNBglEPIJ+Uc1s0UAFFFFABRRRQAUUUUAFZGuaF/bN3pE/2nyTpd59sQeXu3v5bx4PI42yN+OPQg69FABRRRQBjaZoB07xLq+r/afMbVDEZIvLwE8tdq4OfTr6n06Vs0UUAFFFFABRRRQAUUUUAFFFFABRRRQBjeINA/t2TS2+0+QdNvUvU/d7t7qGAB5HGGOe/Tkd9miigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAzvEGkLr/hvUtHklMMeoWslrJIq5Kq6lWI98E49/XpVu0ha3s4oZHDtGgXcq7Qce2TU1FABRRRQAUUUUAFFFFABRRRQAVka5oT6vLaT22rX+lXNqzbJrMxtkMAGBSVHQ9OG27hzggFgdeigChpGkRaRBMqzS3M9zL51zdThBJPJtVNzBFVQdqKPlUDCjir9FFABRRRQAUUUUAFFFFABXM6f4MOn3b48Qarcac1zJdf2bOIGj3vI0pzJ5XmkB2BGXz8oBJHFdNRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAf/Z)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aq2rXj-lCr6S"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy\n",
        "import imageio\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Convolution3D, MaxPooling3D\n",
        "from keras.optimizers import SGD, RMSprop\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils, generic_utils\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import backend as K\n",
        "import sys\n",
        "\n",
        "#K.set_image_dim_ordering('th')\n",
        "K.set_image_data_format('channels_first')"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ccZL9MRC5OT"
      },
      "source": [
        "#Import files from google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZZMuTalC5xB",
        "outputId": "72ce35db-8504-4f15-bfa2-6f9d8c5f636c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRoMmK-5DHjy"
      },
      "source": [
        "#SMIC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pWCmuFODRgR",
        "outputId": "1dec798f-576c-4f63-f11d-124165e3420f"
      },
      "source": [
        "\n",
        "image_rows, image_columns, image_depth = 64, 64, 18\n",
        "\n",
        "training_list = []\n",
        "\n",
        "CODE_PATH = 'drive/MyDrive/MAESTRIA ING DE SISTEMAS/1. MICROEXPRESIONES FACIALES TRABAJO DE GRADO/3. Codigo/microexpresion-recognition-colab'\n",
        "SMIC_path = CODE_PATH + '/datasets/SMIC'\n",
        "CASMEII_path = CODE_PATH + '/datasets/CASMEII'\n",
        "\n",
        "\n",
        "\n",
        "negativepath =SMIC_path +'/SMIC_all_cropped/HS/s1/micro/negative/'\n",
        "positivepath =SMIC_path +'/SMIC_all_cropped/HS/s1/micro/positive/'\n",
        "surprisepath =SMIC_path +'/SMIC_all_cropped/HS/s1/micro/surprise/'\n",
        "\n",
        "\n",
        "print(\"-------------------------negativepath----------------------\")  \n",
        "\n",
        "directorylisting = os.listdir(negativepath)\n",
        "for video in directorylisting:\n",
        "    videopath = negativepath + video\n",
        "    frames = []\n",
        "    framelisting = os.listdir(videopath)\n",
        "    framerange = [x for x in range(18)]\n",
        "\n",
        "\n",
        "\n",
        "    for frame in framerange:\n",
        "           imagepath = videopath + \"/\" + framelisting[frame]\n",
        "           image = cv2.imread(imagepath)\n",
        "           imageresize = cv2.resize(image, (image_rows, image_columns), interpolation = cv2.INTER_AREA)\n",
        "           grayimage = cv2.cvtColor(imageresize, cv2.COLOR_BGR2GRAY)\n",
        "           frames.append(grayimage)\n",
        "    frames = numpy.asarray(frames)\n",
        "    videoarray = numpy.rollaxis(numpy.rollaxis(frames, 2, 0), 2, 0)\n",
        "    \n",
        "    training_list.append(videoarray)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"-------------------------positivepath----------------------\")  \n",
        "\n",
        "directorylisting = os.listdir(positivepath)\n",
        "for video in directorylisting:\n",
        "    videopath = positivepath + video\n",
        "    frames = []\n",
        "    framelisting = os.listdir(videopath)\n",
        "    framerange = [x for x in range(18)]\n",
        "    for frame in framerange:\n",
        "           imagepath = videopath + \"/\" + framelisting[frame]\n",
        "           image = cv2.imread(imagepath)\n",
        "           imageresize = cv2.resize(image, (image_rows, image_columns), interpolation = cv2.INTER_AREA)\n",
        "           grayimage = cv2.cvtColor(imageresize, cv2.COLOR_BGR2GRAY)\n",
        "           frames.append(grayimage)\n",
        "    frames = numpy.asarray(frames)\n",
        "    videoarray = numpy.rollaxis(numpy.rollaxis(frames, 2, 0), 2, 0)\n",
        "    training_list.append(videoarray)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"-------------------------surprisepath----------------------\")  \n",
        "\n",
        "directorylisting = os.listdir(surprisepath)\n",
        "for video in directorylisting:\n",
        "    videopath = surprisepath + video\n",
        "    frames = []\n",
        "    framelisting = os.listdir(videopath)\n",
        "    framerange = [x for x in range(18)]\n",
        "    for frame in framerange:\n",
        "           imagepath = videopath + \"/\" + framelisting[frame]\n",
        "           image = cv2.imread(imagepath)\n",
        "           imageresize = cv2.resize(image, (image_rows, image_columns), interpolation = cv2.INTER_AREA)\n",
        "           grayimage = cv2.cvtColor(imageresize, cv2.COLOR_BGR2GRAY)\n",
        "           frames.append(grayimage)\n",
        "    frames = numpy.asarray(frames)\n",
        "    videoarray = numpy.rollaxis(numpy.rollaxis(frames, 2, 0), 2, 0)\n",
        "    training_list.append(videoarray)\n",
        "\n",
        "training_list = numpy.asarray(training_list)\n",
        "trainingsamples = len(training_list)\n",
        "\n",
        "print(\"len trainingsamples\")\n",
        "print(trainingsamples)\n",
        "\n",
        "\n",
        "\n",
        "traininglabels = numpy.zeros((trainingsamples, ), dtype = int)\n",
        "\n",
        "traininglabels[0:66] = 0\n",
        "traininglabels[66:113] = 1\n",
        "traininglabels[113:156] = 2\n",
        "\n",
        "traininglabels = np_utils.to_categorical(traininglabels, 3)\n",
        "\n",
        "training_data = [training_list, traininglabels]\n",
        "(trainingframes, traininglabels) = (training_data[0], training_data[1])\n",
        "\n",
        "\n",
        "training_set = numpy.zeros((trainingsamples, 1, image_rows, image_columns, image_depth))\n",
        "\n",
        "\n",
        "print(\"range(trainingsamples)\")\n",
        "print(range(trainingsamples))\n",
        "\n",
        "\n",
        "for h in range(trainingsamples):\n",
        "    training_set[h][0][:][:][:] = trainingframes[h, :, :, :]\n",
        "\n",
        "\n",
        "training_set = training_set.astype('float32')\n",
        "training_set -= numpy.mean(training_set)\n",
        "training_set /= numpy.max(training_set)\n",
        "\n",
        "print(\"training_set.shape\")\n",
        "print(training_set.shape)\n",
        "\n",
        "\n",
        "# Save training images and labels in a numpy array\n",
        "numpy.save(CODE_PATH+'/numpy_training_datasets/microexpstcnn_images.npy', training_set)\n",
        "numpy.save(CODE_PATH+'/numpy_training_datasets/microexpstcnn_labels.npy', traininglabels)\n",
        "\n",
        "# Load training images and labels that are stored in numpy array\n",
        "\"\"\"\n",
        "training_set = numpy.load(CODE_PATH+'/numpy_training_datasets/microexpstcnn_images.npy')\n",
        "traininglabels =numpy.load(CODE_PATH+'/numpy_training_datasets/microexpstcnn_labels.npy')\n",
        "\"\"\"\n",
        "\n",
        "# MicroExpSTCNN Model\n",
        "model = Sequential()\n",
        "model.add(Convolution3D(32, (3, 3, 15), input_shape=(1, image_rows, image_columns, image_depth), activation='relu'))\n",
        "model.add(MaxPooling3D(pool_size=(3, 3, 3)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Flatten())\n",
        "#model.add(Dense(128, init='normal', activation='relu'))\n",
        "model.add(Dense(128, kernel_initializer='normal', activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "#model.add(Dense(3, init='normal'))\n",
        "model.add(Dense(3, kernel_initializer='normal'))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'SGD', metrics = ['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "filepath=CODE_PATH+\"/weights_microexpstcnn/weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "#checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "#########filepath=CODE_PATH+\"/weights_microexpstcnn/model_weights.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "# Load pre-trained weights\n",
        "#model.load_weights(CODE_PATH+'/weights_microexpstcnn/weights-improvement-40-0.69.hdf5')\n",
        "model.load_weights(CODE_PATH+'/weights_microexpstcnn/weights-improvement-01-1.00.hdf5')\n",
        "\n",
        "# Spliting the dataset into training and validation sets\n",
        "train_images, validation_images, train_labels, validation_labels =  train_test_split(training_set, traininglabels, test_size=0.2, random_state=4)\n",
        "\n",
        "# Save validation set in a numpy array\n",
        "numpy.save(CODE_PATH+'/numpy_validation_dataset/microexpstcnn_val_images.npy', validation_images)\n",
        "numpy.save(CODE_PATH+'/numpy_validation_dataset/microexpstcnn_val_labels.npy', validation_labels)\n",
        "\n",
        "# Load validation set from numpy array\n",
        "validation_images = numpy.load(CODE_PATH+'/numpy_validation_dataset/microexpstcnn_val_images.npy')\n",
        "validation_labels = numpy.load(CODE_PATH+'/numpy_validation_dataset/microexpstcnn_val_labels.npy')\n",
        "\n",
        "\n",
        "# Training the model\n",
        "#hist = model.fit(train_images, train_labels, validation_data = (validation_images, validation_labels), callbacks=callbacks_list, batch_size = 16, nb_epoch = 100, shuffle=True)\n",
        "hist = model.fit(train_images, train_labels, validation_data = (validation_images, validation_labels), callbacks=callbacks_list, batch_size = 16, epochs = 100, shuffle=True)\n",
        "\n",
        "\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------negativepath----------------------\n",
            "-------------------------positivepath----------------------\n",
            "-------------------------surprisepath----------------------\n",
            "len trainingsamples\n",
            "6\n",
            "range(trainingsamples)\n",
            "range(0, 6)\n",
            "training_set.shape\n",
            "(6, 1, 64, 64, 18)\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv3d_6 (Conv3D)            (None, 32, 62, 62, 4)     4352      \n",
            "_________________________________________________________________\n",
            "max_pooling3d_6 (MaxPooling3 (None, 32, 20, 20, 1)     0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 32, 20, 20, 1)     0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 12800)             0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 128)               1638528   \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 3)                 387       \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 3)                 0         \n",
            "=================================================================\n",
            "Total params: 1,643,267\n",
            "Trainable params: 1,643,267\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1105 - accuracy: 1.0000 - val_loss: 0.0518 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 1.00000, saving model to drive/MyDrive/MAESTRIA ING DE SISTEMAS/1. MICROEXPRESIONES FACIALES TRABAJO DE GRADO/3. Codigo/microexpresion-recognition-colab/weights_microexpstcnn/weights-improvement-01-1.00.hdf5\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0238 - accuracy: 1.0000 - val_loss: 0.0477 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 1.00000\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0733 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 1.00000\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 0.0354 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 1.00000\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.0332 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 1.00000\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0374 - accuracy: 1.0000 - val_loss: 0.0293 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 1.00000\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.0274 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 1.00000\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.0260 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 1.00000\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 0.0242 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 1.00000\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0743 - accuracy: 1.0000 - val_loss: 0.0202 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 1.00000\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.0185 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 1.00000\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 1.00000\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 1.00000\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0399 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 1.00000\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 1.00000\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 1.00000\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 1.00000\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 1.00000\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 1.00000\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0588 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 1.00000\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 1.00000\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 1.00000\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 1.00000\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 1.00000\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 1.00000\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 1.00000\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 1.00000\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 1.00000\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 1.00000\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 1.00000\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 1.00000\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 1.00000\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 1.00000\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 1.00000\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 1.00000\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0332 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 1.00000\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 1.00000\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 1.00000\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 1.00000\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 1.00000\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 1.00000\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 1.00000\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 1.00000\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 1.00000\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 1.00000\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 1.00000\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 1.00000\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 1.00000\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 1.00000\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 1.00000\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 1.00000\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 1.00000\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 1.00000\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 1.00000\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 1.00000\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.2891e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 1.00000\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 1.00000\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 4.2222e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 1.00000\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 1.00000\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 1.00000\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 1.00000\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 1.00000\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 1.00000\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 1.00000\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 8.1955e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 1.00000\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 1.00000\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 1.00000\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 1.00000\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 1.00000\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 1.00000\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 1.00000\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 1.00000\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 1.00000\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 1.00000\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.5296e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 1.00000\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 1.00000\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 1.00000\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 1.00000\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 1.00000\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0318 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 1.00000\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 1.00000\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 1.00000\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 1.00000\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 1.00000\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 1.00000\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 1.00000\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 6.9618e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 1.00000\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 1.00000\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 9.9400e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 1.00000\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 9.6012e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 1.00000\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 9.1278e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 1.00000\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 5.1164e-04 - accuracy: 1.0000 - val_loss: 9.0909e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 1.00000\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 8.9450e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 1.00000\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 6.5511e-04 - accuracy: 1.0000 - val_loss: 8.8991e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 1.00000\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 6.9883e-04 - accuracy: 1.0000 - val_loss: 8.8533e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 1.00000\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 8.7544e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 1.00000\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 8.6317e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 1.00000\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 8.5156e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 1.00000\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 8.2988e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 1.00000\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 8.2345e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 1.00000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxJQ12bdb0d8"
      },
      "source": [
        "#Predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4CzOXL4bzhU",
        "outputId": "7e1ee233-3645-41a4-c09f-ac8025bbe731"
      },
      "source": [
        "\n",
        "# Finding Confusion Matrix using pretrained weights\n",
        "\n",
        "print(\"------------------validation_images--------------------\")\n",
        "print(validation_images.shape)\n",
        "print(validation_images)\n",
        "print(\"------------------validation_labels--------------------\")\n",
        "print(validation_labels.shape)\n",
        "print(validation_labels)\n",
        "\n",
        "\n",
        "\n",
        "predictions = model.predict(validation_images)\n",
        "predictions_labels = numpy.argmax(predictions, axis=1)\n",
        "\n",
        "\n",
        "print(\"-------------------predictions------------------------\")\n",
        "print(predictions)\n",
        "print(\"-------------------predictions_labels-----------------\")\n",
        "print(predictions_labels.shape)\n",
        "print(predictions_labels)\n",
        "\n",
        "validation_labels_y = numpy.argmax(validation_labels, axis=1)\n",
        "\n",
        "\n",
        "\n",
        "print(\"-------------------validation_labels_new---------------\")\n",
        "print(validation_labels_y.shape)\n",
        "print(validation_labels_y)\n",
        "\n",
        "cfm = confusion_matrix(validation_labels_y, predictions_labels)\n",
        "print(\"------------------------------confusion_matrix------------------------------\")\n",
        "print (cfm)\n",
        "\n",
        "print('Accuracy score :', accuracy_score(validation_labels_y,predictions_labels) )\n",
        "\n",
        "\n",
        "print('Classification report :', classification_report(validation_labels_y,predictions_labels) )"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------validation_images--------------------\n",
            "(2, 1, 64, 64, 18)\n",
            "[[[[[-0.349219   -0.35770464 -0.349219   ... -0.35770464 -0.34073332\n",
            "     -0.349219  ]\n",
            "    [-0.29830506 -0.29830506 -0.28981942 ... -0.28981942 -0.2728481\n",
            "     -0.28133374]\n",
            "    [-0.23890549 -0.24739113 -0.25587678 ... -0.25587678 -0.23890549\n",
            "     -0.24739113]\n",
            "    ...\n",
            "    [-0.22193418 -0.23890549 -0.23041983 ... -0.25587678 -0.23890549\n",
            "     -0.23890549]\n",
            "    [-0.23041983 -0.24739113 -0.22193418 ... -0.25587678 -0.23041983\n",
            "     -0.24739113]\n",
            "    [-0.25587678 -0.2728481  -0.25587678 ... -0.2728481  -0.26436245\n",
            "     -0.26436245]]\n",
            "\n",
            "   [[-0.26436245 -0.28133374 -0.25587678 ... -0.2728481  -0.26436245\n",
            "     -0.26436245]\n",
            "    [-0.23041983 -0.23890549 -0.23890549 ... -0.23890549 -0.23890549\n",
            "     -0.23890549]\n",
            "    [-0.20496286 -0.21344852 -0.20496286 ... -0.18799156 -0.18799156\n",
            "     -0.17950591]\n",
            "    ...\n",
            "    [-0.21344852 -0.23890549 -0.23041983 ... -0.24739113 -0.23890549\n",
            "     -0.23041983]\n",
            "    [-0.22193418 -0.23890549 -0.23041983 ... -0.24739113 -0.23890549\n",
            "     -0.23890549]\n",
            "    [-0.23041983 -0.24739113 -0.23041983 ... -0.24739113 -0.22193418\n",
            "     -0.24739113]]\n",
            "\n",
            "   [[-0.25587678 -0.25587678 -0.24739113 ... -0.24739113 -0.24739113\n",
            "     -0.23890549]\n",
            "    [-0.21344852 -0.23890549 -0.22193418 ... -0.21344852 -0.21344852\n",
            "     -0.21344852]\n",
            "    [-0.14556329 -0.14556329 -0.14556329 ... -0.13707764 -0.12010633\n",
            "     -0.12859198]\n",
            "    ...\n",
            "    [-0.22193418 -0.23890549 -0.21344852 ... -0.23890549 -0.23041983\n",
            "     -0.24739113]\n",
            "    [-0.23041983 -0.23041983 -0.22193418 ... -0.23890549 -0.23041983\n",
            "     -0.23890549]\n",
            "    [-0.21344852 -0.23890549 -0.21344852 ... -0.22193418 -0.21344852\n",
            "     -0.23041983]]\n",
            "\n",
            "   ...\n",
            "\n",
            "   [[-0.5528747  -0.5528747  -0.5528747  ... -0.5528747  -0.5528747\n",
            "     -0.5528747 ]\n",
            "    [-0.544389   -0.5528747  -0.5528747  ... -0.544389   -0.56136036\n",
            "     -0.5528747 ]\n",
            "    [-0.5528747  -0.5528747  -0.5528747  ... -0.5528747  -0.56136036\n",
            "     -0.5528747 ]\n",
            "    ...\n",
            "    [-0.5274177  -0.5359034  -0.5359034  ... -0.5274177  -0.5359034\n",
            "     -0.5274177 ]\n",
            "    [-0.5359034  -0.5359034  -0.5359034  ... -0.5359034  -0.5359034\n",
            "     -0.5359034 ]\n",
            "    [-0.5274177  -0.5359034  -0.5359034  ... -0.544389   -0.5359034\n",
            "     -0.544389  ]]\n",
            "\n",
            "   [[-0.5528747  -0.5528747  -0.544389   ... -0.5528747  -0.544389\n",
            "     -0.544389  ]\n",
            "    [-0.5528747  -0.5528747  -0.5528747  ... -0.5528747  -0.56136036\n",
            "     -0.5528747 ]\n",
            "    [-0.5528747  -0.5528747  -0.5528747  ... -0.5528747  -0.5528747\n",
            "     -0.5528747 ]\n",
            "    ...\n",
            "    [-0.5274177  -0.5359034  -0.5359034  ... -0.544389   -0.5359034\n",
            "     -0.544389  ]\n",
            "    [-0.5359034  -0.5359034  -0.5359034  ... -0.5359034  -0.5359034\n",
            "     -0.544389  ]\n",
            "    [-0.5359034  -0.544389   -0.544389   ... -0.544389   -0.5359034\n",
            "     -0.5528747 ]]\n",
            "\n",
            "   [[-0.5528747  -0.5528747  -0.5528747  ... -0.56136036 -0.5528747\n",
            "     -0.5528747 ]\n",
            "    [-0.5528747  -0.5528747  -0.56136036 ... -0.5528747  -0.5528747\n",
            "     -0.5528747 ]\n",
            "    [-0.56136036 -0.5528747  -0.5528747  ... -0.56136036 -0.5528747\n",
            "     -0.56136036]\n",
            "    ...\n",
            "    [-0.5359034  -0.544389   -0.5359034  ... -0.5274177  -0.5359034\n",
            "     -0.5359034 ]\n",
            "    [-0.544389   -0.544389   -0.5359034  ... -0.544389   -0.5359034\n",
            "     -0.5359034 ]\n",
            "    [-0.544389   -0.5528747  -0.544389   ... -0.544389   -0.544389\n",
            "     -0.544389  ]]]]\n",
            "\n",
            "\n",
            "\n",
            " [[[[-0.349219   -0.349219   -0.349219   ... -0.34073332 -0.33224767\n",
            "     -0.349219  ]\n",
            "    [-0.29830506 -0.29830506 -0.29830506 ... -0.32376203 -0.31527638\n",
            "     -0.33224767]\n",
            "    [-0.22193418 -0.23041983 -0.22193418 ... -0.25587678 -0.23890549\n",
            "     -0.24739113]\n",
            "    ...\n",
            "    [-0.25587678 -0.25587678 -0.26436245 ... -0.25587678 -0.24739113\n",
            "     -0.25587678]\n",
            "    [-0.25587678 -0.28133374 -0.26436245 ... -0.26436245 -0.26436245\n",
            "     -0.2728481 ]\n",
            "    [-0.28133374 -0.3067907  -0.29830506 ... -0.29830506 -0.28133374\n",
            "     -0.28981942]]\n",
            "\n",
            "   [[-0.31527638 -0.33224767 -0.32376203 ... -0.35770464 -0.349219\n",
            "     -0.36619028]\n",
            "    [-0.23890549 -0.24739113 -0.23890549 ... -0.26436245 -0.25587678\n",
            "     -0.2728481 ]\n",
            "    [-0.21344852 -0.23041983 -0.22193418 ... -0.23041983 -0.21344852\n",
            "     -0.22193418]\n",
            "    ...\n",
            "    [-0.21344852 -0.23890549 -0.22193418 ... -0.23890549 -0.21344852\n",
            "     -0.23890549]\n",
            "    [-0.24739113 -0.25587678 -0.24739113 ... -0.25587678 -0.24739113\n",
            "     -0.25587678]\n",
            "    [-0.2728481  -0.2728481  -0.26436245 ... -0.2728481  -0.25587678\n",
            "     -0.26436245]]\n",
            "\n",
            "   [[-0.22193418 -0.23890549 -0.23041983 ... -0.25587678 -0.23890549\n",
            "     -0.24739113]\n",
            "    [-0.23041983 -0.24739113 -0.23041983 ... -0.23890549 -0.23041983\n",
            "     -0.23041983]\n",
            "    [-0.20496286 -0.22193418 -0.20496286 ... -0.23890549 -0.22193418\n",
            "     -0.23890549]\n",
            "    ...\n",
            "    [-0.21344852 -0.22193418 -0.21344852 ... -0.22193418 -0.21344852\n",
            "     -0.22193418]\n",
            "    [-0.23041983 -0.23041983 -0.22193418 ... -0.23041983 -0.22193418\n",
            "     -0.23041983]\n",
            "    [-0.25587678 -0.25587678 -0.23890549 ... -0.26436245 -0.23890549\n",
            "     -0.25587678]]\n",
            "\n",
            "   ...\n",
            "\n",
            "   [[-0.5359034  -0.544389   -0.544389   ... -0.5528747  -0.544389\n",
            "     -0.544389  ]\n",
            "    [-0.5359034  -0.544389   -0.544389   ... -0.5359034  -0.544389\n",
            "     -0.5359034 ]\n",
            "    [-0.51893204 -0.5274177  -0.51893204 ... -0.5359034  -0.5359034\n",
            "     -0.5274177 ]\n",
            "    ...\n",
            "    [-0.5528747  -0.56136036 -0.56136036 ... -0.5528747  -0.5528747\n",
            "     -0.5528747 ]\n",
            "    [-0.5528747  -0.56136036 -0.56136036 ... -0.56136036 -0.56136036\n",
            "     -0.56136036]\n",
            "    [-0.5528747  -0.5528747  -0.5528747  ... -0.56136036 -0.56136036\n",
            "     -0.5528747 ]]\n",
            "\n",
            "   [[-0.544389   -0.5528747  -0.5528747  ... -0.5528747  -0.544389\n",
            "     -0.544389  ]\n",
            "    [-0.544389   -0.5528747  -0.544389   ... -0.5528747  -0.5528747\n",
            "     -0.5528747 ]\n",
            "    [-0.5274177  -0.5359034  -0.5359034  ... -0.5359034  -0.5359034\n",
            "     -0.5359034 ]\n",
            "    ...\n",
            "    [-0.5528747  -0.5528747  -0.5528747  ... -0.5528747  -0.5528747\n",
            "     -0.5528747 ]\n",
            "    [-0.5528747  -0.5528747  -0.5528747  ... -0.56136036 -0.5528747\n",
            "     -0.5528747 ]\n",
            "    [-0.5528747  -0.5528747  -0.5528747  ... -0.56136036 -0.56136036\n",
            "     -0.56136036]]\n",
            "\n",
            "   [[-0.5528747  -0.5528747  -0.544389   ... -0.5528747  -0.544389\n",
            "     -0.544389  ]\n",
            "    [-0.5528747  -0.5528747  -0.5528747  ... -0.5528747  -0.544389\n",
            "     -0.5528747 ]\n",
            "    [-0.5359034  -0.544389   -0.544389   ... -0.544389   -0.5359034\n",
            "     -0.5528747 ]\n",
            "    ...\n",
            "    [-0.56136036 -0.56136036 -0.56136036 ... -0.5528747  -0.5528747\n",
            "     -0.5528747 ]\n",
            "    [-0.5528747  -0.5528747  -0.5528747  ... -0.5528747  -0.5528747\n",
            "     -0.5528747 ]\n",
            "    [-0.544389   -0.544389   -0.544389   ... -0.5528747  -0.5528747\n",
            "     -0.5528747 ]]]]]\n",
            "------------------validation_labels--------------------\n",
            "(2, 3)\n",
            "[[1. 0. 0.]\n",
            " [1. 0. 0.]]\n",
            "-------------------predictions------------------------\n",
            "[[9.9927753e-01 4.5321509e-04 2.6917370e-04]\n",
            " [9.9907625e-01 5.2620837e-04 3.9751100e-04]]\n",
            "-------------------predictions_labels-----------------\n",
            "(2,)\n",
            "[0 0]\n",
            "-------------------validation_labels_new---------------\n",
            "(2,)\n",
            "[0 0]\n",
            "------------------------------confusion_matrix------------------------------\n",
            "[[2]]\n",
            "Accuracy score : 1.0\n",
            "Classification report :               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00         2\n",
            "   macro avg       1.00      1.00      1.00         2\n",
            "weighted avg       1.00      1.00      1.00         2\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9774PQimH76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c53f8021-5aa5-4e23-f96d-37bfcf9b5c8c"
      },
      "source": [
        "train_images.shape\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 1, 64, 64, 18)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neIf_f3AezRr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb24b805-a68d-4828-d701-ad914cd8bb69"
      },
      "source": [
        "validation_images.shape"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1, 64, 64, 18)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEy85eSRmvUE"
      },
      "source": [
        "\n",
        "#y_predit = model.predict(train_images[:,:,:,:,14])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#revisar x el que el train_images.shape esta dando con el  4, 1\n",
        "\n",
        "\n",
        "#revisar el modelo \n",
        "\n",
        "#por que los traingns deben ser asi\n",
        "#traings\n",
        "#1, 64, 64, 3\n",
        "\n",
        "#todas las imagenes \n",
        "#18, 1, 64, 64, 3\n",
        "\n",
        "#y revisar por que solo se tienen 18 imagenes"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ho7Gp2bz9bGf"
      },
      "source": [
        "#Save model as json string"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cOmqIRC9hZC"
      },
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)"
      ],
      "execution_count": 54,
      "outputs": []
    }
  ]
}